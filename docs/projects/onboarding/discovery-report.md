# Phase 2 Onboarding — Discovery Report

> **Generated by:** Pipeline Stage 1 (Discovery)
> **Date:** 2026-02-07
> **PRD:** `onboarding/prd.md`

---

## 1. PRD Understanding

### Feature Summary

Enable automatic AI processing of all new podcast episodes (currently requires manual Library add) and redesign the daily digest email from a notification ("stuff is waiting in the app") into a newsletter ("here's what your podcasts are about today") with AI summaries for every episode. Add internal redirect-based click tracking and pixel-based open tracking to measure engagement. Backfill ~10 most recent unprocessed episodes per podcast.

### Entities Identified

| Entity | PRD Reference | Existing? | Current Location |
|--------|--------------|-----------|-----------------|
| Episode | AUTO-001, DIG-002 | Yes | `app/models/episode.rb` |
| Podcast | DIG-009, AUTO-001 | Yes | `app/models/podcast.rb` |
| User | DIG-012, TRK-001 | Yes | `app/models/user.rb` |
| Subscription | AUTO-001 | Yes | `app/models/subscription.rb` |
| UserEpisode | AUTO-002, DIG-001 | Yes | `app/models/user_episode.rb` |
| Transcript | AUTO-003 | Yes | `app/models/transcript.rb` |
| Summary | AUTO-003, DIG-002 | Yes | `app/models/summary.rb` |
| DigestMailer | DIG-011 | Yes | `app/mailers/digest_mailer.rb` |
| SendDailyDigestJob | DIG-012 | Yes | `app/jobs/send_daily_digest_job.rb` |
| ProcessEpisodeJob | AUTO-003 | Yes | `app/jobs/process_episode_job.rb` |
| FetchPodcastFeedJob | AUTO-001 | Yes | `app/jobs/fetch_podcast_feed_job.rb` |
| RefreshAllFeedsJob | AUTO-001 | Yes | `app/jobs/refresh_all_feeds_job.rb` |
| Email open tracking | TRK-001 | No | N/A — new |
| Email click tracking | TRK-002, TRK-003 | No | N/A — new |
| Engagement tracking model | TRK-004 | No | N/A — new |

### Platforms Affected

- [x] Rails (Web)
- [ ] Rails (API)
- [ ] iOS
- [ ] Android

---

## 2. Current State: Primary Platform

### Related Models

| Model | File | Key Associations | Notes |
|-------|------|------------------|-------|
| User | `app/models/user.rb` | `has_many :subscriptions`, `has_many :podcasts, through: :subscriptions`, `has_many :user_episodes` | Has `digest_enabled` (bool, default true) and `digest_sent_at` (datetime). Magic link auth. |
| Podcast | `app/models/podcast.rb` | `has_many :subscriptions`, `has_many :users, through: :subscriptions`, `has_many :episodes` | Validates guid (unique), title, feed_url. `last_fetched_at` tracks polling. |
| Subscription | `app/models/subscription.rb` | `belongs_to :user`, `belongs_to :podcast` | Join table. Unique index on (user_id, podcast_id). |
| Episode | `app/models/episode.rb` | `belongs_to :podcast`, `has_many :user_episodes`, `has_one :transcript`, `has_one :summary` | Validates guid (unique per podcast_id), title, audio_url. Has `estimated_cost_cents` method. |
| UserEpisode | `app/models/user_episode.rb` | `belongs_to :user`, `belongs_to :episode` | Enums: `location` (inbox/library/archive/trash), `processing_status` (pending/downloading/transcribing/summarizing/ready/error). Delegates title, podcast, summary etc to episode. Scopes: `in_inbox`, `in_library`, etc. |
| Transcript | `app/models/transcript.rb` | `belongs_to :episode` | One per episode (shared across users). Content is JSON text from AssemblyAI. |
| Summary | `app/models/summary.rb` | `belongs_to :episode` | One per episode (shared). `sections` (JSON array of {title, content, start_time, end_time}), `quotes` (JSON array of {text, start_time}), `searchable_text`. |

### Current Schema (Related Tables)

```sql
-- users
create_table "users" do |t|
  t.string "email"                                       -- unique index
  t.string "magic_token"
  t.datetime "magic_token_expires_at"
  t.boolean "digest_enabled", default: true, null: false
  t.datetime "digest_sent_at"
  t.timestamps
end

-- podcasts
create_table "podcasts" do |t|
  t.string "guid"                                        -- unique index
  t.string "title"
  t.string "author"
  t.text "description"
  t.string "feed_url"                                    -- unique index
  t.string "artwork_url"
  t.datetime "last_fetched_at"
  t.timestamps
end

-- subscriptions
create_table "subscriptions" do |t|
  t.bigint "user_id", null: false                        -- FK to users
  t.bigint "podcast_id", null: false                     -- FK to podcasts
  t.timestamps
  -- unique index on (user_id, podcast_id)
end

-- episodes
create_table "episodes" do |t|
  t.bigint "podcast_id", null: false                     -- FK to podcasts
  t.string "guid"
  t.string "title"
  t.text "description"
  t.string "audio_url"
  t.integer "duration_seconds"
  t.datetime "published_at"
  t.timestamps
  -- unique index on (podcast_id, guid)
end

-- user_episodes
create_table "user_episodes" do |t|
  t.bigint "user_id", null: false                        -- FK to users
  t.bigint "episode_id", null: false                     -- FK to episodes
  t.integer "location", default: 0, null: false          -- enum: inbox(0), library(1), archive(2), trash(3)
  t.integer "processing_status", default: 0, null: false -- enum: pending(0)..error(5)
  t.text "processing_error"
  t.integer "retry_count", default: 0, null: false
  t.datetime "next_retry_at"
  t.datetime "last_error_at"
  t.datetime "trashed_at"
  t.timestamps
  -- unique index on (user_id, episode_id)
end

-- transcripts
create_table "transcripts" do |t|
  t.bigint "episode_id", null: false                     -- FK to episodes
  t.text "content"                                       -- JSON from AssemblyAI
  t.timestamps
end

-- summaries
create_table "summaries" do |t|
  t.bigint "episode_id", null: false                     -- FK to episodes
  t.json "sections"                                      -- [{title, content, start_time, end_time}]
  t.json "quotes"                                        -- [{text, start_time}]
  t.text "searchable_text"
  t.timestamps
end
```

### Related Controllers

| Controller | File | Actions | Auth Pattern |
|-----------|------|---------|--------------|
| ApplicationController | `app/controllers/application_controller.rb` | N/A (base) | `before_action :require_authentication` — finds user from `session[:user_id]` |
| LibraryController | `app/controllers/library_controller.rb` | index, show, archive, regenerate | Standard auth. Show action is the episode detail page with audio player. |
| InboxController | `app/controllers/inbox_controller.rb` | index, create, add_to_library, skip, clear | `add_to_library` enqueues `ProcessEpisodeJob`. |
| ImportsController | `app/controllers/imports_controller.rb` | new, create, select_favorites, process_favorites, complete | Custom auth (allows public import page). `process_favorites` enqueues `ProcessEpisodeJob` per selected podcast. |
| SettingsController | `app/controllers/settings_controller.rb` | show, update | Updates `digest_enabled` only (whitelist). |
| SessionsController | `app/controllers/sessions_controller.rb` | new, create, sent, verify, destroy | Magic link auth. `previously_new_record?` detection for signup notifications. |

### Related Serializers

N/A — Show Notes is a web-only app with no API. Views use ERB templates directly.

### Related API Endpoints (Current)

N/A — no API endpoints. All routes serve HTML views.

### Current API Response Examples

N/A — web-only.

### Related Tests

| Test File | Coverage | Type |
|-----------|----------|------|
| `spec/mailers/digest_mailer_spec.rb` | Inbox section (5 episode limit, +N more), library section (summaries, quotes), empty state, unsubscribe footer | Mailer |
| `spec/jobs/send_daily_digest_job_spec.rb` | Sends to users with content, skips no-content users, skips digest-disabled, updates digest_sent_at, filters old/pending library episodes | Job |
| `spec/jobs/process_episode_job_spec.rb` | (exists) Transcription, summarization, retry logic, shared processing optimization | Job |
| `spec/jobs/refresh_all_feeds_job_spec.rb` | (exists) Enqueues per-podcast feed jobs | Job |
| `spec/models/user_episode_spec.rb` | Location moves, processing_status, scopes, validations | Model |
| `spec/models/episode_spec.rb` | Validations, cost estimation | Model |
| `spec/models/user_spec.rb` | Magic token, validations | Model |
| `spec/requests/settings_spec.rb` | Show/update, digest_enabled toggle, digest_sent_at display | Request |
| `spec/requests/inbox_spec.rb` | Inbox display, add_to_library, skip, clear, pagination | Request |
| `spec/requests/library_spec.rb` | Library display, pagination, empty state | Request |
| `spec/requests/imports_spec.rb` | OPML upload, favorites selection, processing, cost display | Request |
| `spec/services/opml_import_service_spec.rb` | subscribe_all, process_favorites, dedup, error handling | Service |

### Related Background Jobs

| Job | File | Purpose | Schedule |
|-----|------|---------|----------|
| FetchPodcastFeedJob | `app/jobs/fetch_podcast_feed_job.rb` | Parses RSS feed, creates Episodes, creates UserEpisodes in inbox for subscribers. On `initial_fetch`, limits to 10 most recent. | On-demand (subscribe, hourly refresh) |
| RefreshAllFeedsJob | `app/jobs/refresh_all_feeds_job.rb` | Enqueues FetchPodcastFeedJob for every podcast with ≥1 subscriber. | Hourly (production), every 15 min (dev) |
| ProcessEpisodeJob | `app/jobs/process_episode_job.rb` | Transcribes (AssemblyAI) + summarizes (Claude) an episode. Takes `user_episode_id`. Shared transcript/summary optimization. Exponential backoff retries (5 max). | On-demand (add to library, OPML favorites) |
| SendDailyDigestJob | `app/jobs/send_daily_digest_job.rb` | Sends digest email to all digest-enabled users with content. | Daily at 12 PM UTC (7 AM Eastern) |
| CleanupTrashJob | `app/jobs/cleanup_trash_job.rb` | Deletes UserEpisodes trashed >90 days ago. | Daily at 3 AM |

---

## 3. Current State: iOS

N/A — Level 2 (web-only) project.

---

## 4. Current State: Android

N/A — Level 2 (web-only) project.

---

## 5. Cross-Platform Patterns

### Data Flow

```
RSS Feed → PodcastFeedParser → Episode (shared) → UserEpisode (per-user)
                                                        ↓ (manual: add to library)
                                              ProcessEpisodeJob
                                                        ↓
                                              AssemblyAI → Transcript (shared per episode)
                                                        ↓
                                              Claude → Summary (shared per episode)
                                                        ↓
                                              UserEpisode.processing_status = :ready
                                                        ↓
                                              DigestMailer (daily) → Email
```

### Key Architectural Pattern: Shared vs Per-User

The app cleanly separates shared data from per-user data:

- **Shared (one per episode):** Episode, Transcript, Summary
- **Per-user:** UserEpisode (tracks location, processing_status for that user's copy)
- **ProcessEpisodeJob optimization (line 14-18):** If another user already processed an episode, the job skips transcription/summarization and just marks the UserEpisode as ready.

This is critical for the auto-processing feature — the transcript and summary are created once, then all subscribers benefit.

### How the Existing Digest Email Works

1. **SendDailyDigestJob** runs at 7 AM Eastern for all users with `digest_enabled: true`
2. **Decision logic (`should_send_digest?`):** Send if user has inbox episodes OR recently-ready library episodes (updated in last 2 days)
3. **DigestMailer#daily_digest** queries:
   - `@inbox_episodes`: Up to 5 inbox episodes, by published_at DESC
   - `@library_episodes`: Up to 2 library episodes in `ready` status, updated in last 2 days, with summaries
   - `@inbox_count`: Total inbox count (for "+N more" indicator)
4. **Email template:** Two sections — "Inbox (N new episodes)" with titles only, "Recently Ready" with truncated summaries (first 2 sections at 200 chars, 1 quote at 150 chars)
5. **Subject line:** "Your Daily Podcast Digest - Feb 07"

### How Processing is Currently Triggered

Processing is **user-action gated** — it only happens when:
1. User clicks "Add to Library" in inbox → `InboxController#add_to_library` → `ProcessEpisodeJob`
2. User selects favorites during OPML import → `ImportsController#process_favorites` → `ProcessEpisodeJob`

There is **no automatic processing trigger** when new episodes arrive via feed polling. `FetchPodcastFeedJob` creates Episodes and UserEpisodes (in inbox), but does NOT enqueue `ProcessEpisodeJob`.

### How the OPML Import Flow Works

1. **Upload:** `ImportsController#create` → `OpmlParser.parse(xml)` → `OpmlImportService.subscribe_all(user, feeds)`
   - Creates Podcast + Subscription records. Does NOT enqueue any jobs.
2. **Favorites selection:** `ImportsController#select_favorites` shows checkboxes with cost estimates
3. **Processing:** `ImportsController#process_favorites` → `OpmlImportService.process_favorites(user, podcast_ids)`
   - For each selected podcast: fetches latest episode, creates Episode + UserEpisode (in library), enqueues ProcessEpisodeJob
4. **Completion:** Shows "We're processing your favorite shows now. Your first digest arrives tomorrow morning."

### How the Library Show Page Works (Episode Detail with Player)

`LibraryController#show` renders `views/library/show.html.erb` which has:
- Episode title and podcast name
- Full summary (all sections + all quotes with timestamps)
- Collapsible "Original Show Notes" (episode description)
- Audio player (`<audio>` element with `src=episode.audio_url`)
- "Mark as Done" (archive) and "Regenerate Summary" buttons
- Processing/error states for in-progress episodes

This is the page that DIG-003 "Read full summary" and DIG-004 "Listen" links should point to.

### Routing Patterns

The library show route uses `library_path(user_episode)` (not `library_path(episode)`). The URL is `/library/:id` where `:id` is the UserEpisode ID. This means the digest "Read full summary" link currently needs a UserEpisode, not an Episode.

**This is a key constraint for the redesigned digest:** For auto-processed episodes that the user hasn't explicitly added to Library, there may be no UserEpisode in `library` location — the episode might be in `inbox` or might not have a UserEpisode at all. The digest link strategy needs to account for this.

---

## 6. Technical Risks

| Risk | Severity | Details | Mitigation |
|------|----------|---------|------------|
| Processing trigger architecture change | High | Currently processing is gated by user action (add to Library). Auto-processing means triggering ProcessEpisodeJob from FetchPodcastFeedJob or a new job — fundamentally changes the episode lifecycle. | New job or modification to FetchPodcastFeedJob. Keep the shared transcript/summary optimization intact. |
| Digest query scope change | High | Current digest queries UserEpisode (inbox + library). New digest needs ALL new episodes for a user's subscriptions — even episodes the user hasn't interacted with. Query must go through Subscription → Podcast → Episode → Summary, not through UserEpisode. | New query path in DigestMailer. Use `user.digest_sent_at` as the "since" cutoff. |
| Library show page requires UserEpisode | Med | `library_path(user_episode)` expects a UserEpisode record. Auto-processed episodes may not have a UserEpisode in library. Digest links need a different route or strategy. | Either create UserEpisode on-demand when user clicks through, or add a new episode detail route that doesn't require UserEpisode. |
| Cost explosion from auto-processing | Med | At ~$0.46/episode × 50 episodes/user/week × 3 users = ~$69/week. PRD accepts this for the test, but auto-processing has no cap and processes everything. A runaway feed or unexpected subscriber could spike costs. | PRD explicitly accepts this risk for Phase 2. Consider adding a per-user weekly cost tracking field for observability. |
| ProcessEpisodeJob takes `user_episode_id` | Med | The job is designed around a specific user's episode copy. Auto-processing needs to process the episode itself (transcript + summary) independent of any particular user. Job interface may need a new entry point. | Either add an alternative `perform` signature that takes `episode_id`, or create a new `AutoProcessEpisodeJob` that calls the same transcription/summarization logic. |
| Backfill volume burst | Med | AUTO-007 backfills ~10 episodes per podcast. A user with 30 podcasts = 300 episodes queued simultaneously. At $0.46/episode = ~$138 if all need processing. | Queue with low priority. Rate-limit API calls already exist (2-sec Claude delay, exponential backoff). Cost is within acceptable range per PRD. |
| No tracking infrastructure exists | Low | Email tracking (pixels, redirect links) requires new routes, a new model, and changes to the mailer. Not complex but is entirely new code. | Standard pattern. Rails redirect controller + tracking model. Tracking pixel is a 1x1 transparent GIF served from a new route. |
| Email deliverability with tracking pixel | Low | Some email clients (Gmail, Outlook) proxy images. Tracking pixel may fire from proxy, not user. Open tracking has inherent unreliability. | PRD acknowledges this (edge case: "Tracking pixel blocked by email client"). Clicks are more reliable than opens. |

### Performance Concerns

- **Digest email size:** All episodes with summaries could create large emails for users with 50+ episodes/day. Email clients have size limits (~102KB for Gmail clipping). Need to keep per-episode summary to 2-3 sentences in the email.
- **Digest query:** The new query (all episodes since last digest, with summaries, grouped by show) is more complex than the current query. Needs proper indexing on `episodes.published_at` and `episodes.podcast_id` (both have indexes).
- **Auto-processing queue depth:** 50 episodes/user × 3 users = 150 jobs. Each takes 2-5 minutes (AssemblyAI transcription). Solid Queue runs in-process via Puma — need to verify concurrent job capacity.

### Security Concerns

- **Tracking redirect links:** Must validate the destination URL to prevent open redirect vulnerability. Only allow redirects to internal Show Notes URLs.
- **Tracking pixel:** Ensure the pixel endpoint doesn't leak user information in URL parameters. Use opaque token IDs, not user IDs.

---

## 7. Open Questions

| # | Question | Source | Blocking? |
|---|----------|--------|-----------|
| 1 | The library show page requires a UserEpisode (`library_path(user_episode)`). For auto-processed episodes without a library UserEpisode, what should the "Read full summary" link point to? Options: (a) Create a new episode detail route, (b) Auto-create UserEpisode in library when user clicks, (c) Use the existing library route but change it to accept episode_id. | Code: `routes.rb:25`, `library_controller.rb:8` | Yes — affects routing architecture |
| 2 | Should auto-processing create UserEpisode records in a new location (e.g., none/neutral), or should processing happen at the Episode level without creating UserEpisodes? The current lifecycle is inbox→library→archive, and UserEpisode carries processing_status. | Code: `user_episode.rb:5-13`, `process_episode_job.rb:7-8` | Yes — affects data model |
| 3 | The current `ProcessEpisodeJob.perform(user_episode_id)` is scoped to a single user's episode. Auto-processing needs to process the Episode itself (shared transcript + summary). Should the existing job be adapted or should a new episode-level job be created? | Code: `process_episode_job.rb:7-8` | No — implementation detail for Stage 2 |
| 4 | `FetchPodcastFeedJob` already limits to 10 episodes on `initial_fetch`. Should auto-processing re-use this same job (adding a processing trigger), or should backfill be a separate job? | Code: `fetch_podcast_feed_job.rb:11` | No — implementation detail for Stage 2 |
| 5 | The current digest subject is "Your Daily Podcast Digest - Feb 07". PRD specifies "Your podcasts this morning — 14 new episodes". Should the plain-text template structure also change to match the newsletter format (grouped by show, summaries)? | Code: `daily_digest.text.erb`, PRD DIG-007 | No — confirmed by PRD, text template follows HTML |
| 6 | For click tracking redirect links, what URL structure? e.g., `/t/:token` (opaque) vs `/track/click/:tracking_id` (descriptive)? | PRD TRK-002, TRK-003 | No — implementation detail |

---

## 8. Recommendations for Architecture Stage

- **Follow the shared processing pattern.** The existing architecture cleanly separates Episode (shared) from UserEpisode (per-user). Auto-processing should trigger at the Episode level, not the UserEpisode level. The `ProcessEpisodeJob` optimization (skip if transcript+summary exist) already supports this.
- **The digest query needs a fundamentally different data source.** Current digest uses `user.user_episodes`. New digest needs `Episode.joins(podcast: :subscriptions).where(subscriptions: { user_id: user.id }).where("episodes.created_at > ?", user.digest_sent_at)` (or similar). This is the biggest structural change.
- **Consider an episode-show route for digest links.** The library show page has the right content (summary + audio player) but requires UserEpisode. A new route like `/episodes/:id` that shows the same content for any episode the user is subscribed to would cleanly solve the linking problem.
- **The existing digest mailer can be adapted in-place.** The template structure changes significantly, but the mailer class, job, scheduling, and user settings (`digest_enabled`, `digest_sent_at`) are all reusable.
- **Email tracking is additive, not invasive.** A new model (e.g., `EmailEvent`), a new controller for redirects/pixel, and token generation in the mailer. Doesn't require changes to existing models.
- **Auto-processing trigger belongs in FetchPodcastFeedJob.** When a new episode is discovered, it's the natural place to enqueue processing. The backfill (~10 per podcast) is a one-time operation that can be a rake task or a separate job.
- **The existing import completion page already has the right messaging.** `imports/complete.html.erb` says "Your first digest arrives tomorrow morning." — ONB-002 may already be satisfied for OPML import users.
