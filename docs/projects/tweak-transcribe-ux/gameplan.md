---
pipeline_stage: 3
pipeline_stage_name: gameplan
pipeline_project: "tweak-transcribe-ux"
pipeline_started_at: "2026-02-10T06:39:13-0500"
pipeline_completed_at: "2026-02-10T06:39:41-0500"
pipeline_approved_at: "2026-02-10T00:00:00-0500"
---

# Transcription Resilience & Retry UX — Engineering Gameplan

> **Generated by:** Pipeline Stage 3 (Gameplan)
> **Date:** 2026-02-10
> **PRD:** `~/projects/show-notes/pipeline-projects/tweak-transcribe-ux/prd.md`
> **Discovery Report:** `~/projects/show-notes/pipeline-projects/tweak-transcribe-ux/discovery-report.md`
> **Approved Architecture:** `~/projects/show-notes/pipeline-projects/tweak-transcribe-ux/architecture-proposal.md`

---

## 1. Project Overview

### Goals
- Eliminate permanently-stuck transcription states by closing error handling gaps in both job pathways
- Throttle concurrent transcription jobs to prevent rate limit exhaustion during bulk import
- Surface processing status, errors, and retry in the Inbox tab (matching Library tab treatment)
- Detect and recover episodes stuck in transitional states via recurring timeout job

### Scope Summary

| Area | Description | Platform |
|------|-------------|----------|
| Error handling fixes | Close gaps in ProcessEpisodeJob and AutoProcessEpisodeJob | Web |
| Concurrency throttling | Solid Queue `limits_concurrency` on both job types | Web |
| Stuck job detection | New recurring DetectStuckProcessingJob | Web |
| Inbox UX | Add processing status, error display, retry button | Web |
| Library UX | Enhance error display on index, rewire show retry | Web |
| Rate limit detection | AssemblyAiClient raises RateLimitError on 429 | Web |
| Episode-level state | New processing columns on episodes table | Web |

### Out of Scope
- AssemblyAI usage dashboard or quota monitoring
- Alternative transcription provider fallback
- Bulk retry for multiple failed episodes at once
- Webhook/push notification when transcription fails
- Changing the existing exponential backoff parameters

### Constraints & Conventions
- AGENTS.md: `~/projects/show-notes/AGENTS.md`
- CLAUDE.md: `~/projects/show-notes/CLAUDE.md`
- Turbo Drive requires PRG (Post/Redirect/Get) pattern for form submissions
- No feature flag — ship directly

---

## 2. Open Questions & Decisions

> Resolved during Stages 1-2 (Discovery + Architecture)

| Question | Status | Decision |
|----------|--------|----------|
| What exception does AssemblyAI raise on rate limit? | Resolved | `Faraday::TooManyRequestsError` (subclass of `Faraday::Error`). Currently caught and wrapped as generic `Error`. Fix: rescue specifically and raise `RateLimitError`. |
| How should AutoProcessEpisodeJob report errors? | Resolved | Add `processing_status`, `processing_error`, `last_error_at` columns to `episodes` table. |
| Should jobs be unified or kept separate? | Resolved | Keep separate — different state tracking targets (UserEpisode vs Episode). |
| Concurrency limit value? | Resolved | `to: 3` — conservative, easy to increase later. |
| Stuck job threshold? | Resolved | 30 minutes — 2x margin over typical AssemblyAI transcription time. |
| Retry vs regenerate? | Resolved | New `retry_processing` action resets to `:pending`. Existing `regenerate` stays for re-summarizing ready episodes. |

---

## 3. Functional Milestones

> Organized by FEATURE AREA, not by platform.

### M0: Discovery & Alignment (Complete)
- [x] PRD parsed and understood (Stage 1)
- [x] Current state documented (Stage 1)
- [x] Data model proposed and **approved** (Stage 2 + Architecture Review)
- [x] Open questions resolved (Stages 1-2)

---

### M1: Data Model & Core Error Handling
**What:** Add episode-level processing state columns, fix error handling in both jobs, add AssemblyAI rate limit detection, add Solid Queue concurrency throttling. This is the foundation — everything else depends on these backend fixes.
**Size:** M

**Acceptance Criteria:**
- [ ] ERR-001: `ProcessEpisodeJob` catches all exception types and transitions `user_episode.processing_status` to `:error` with a descriptive `processing_error` message — including rate limits, API errors, and unexpected exceptions
- [ ] ERR-001: `AutoProcessEpisodeJob` catches all exception types and transitions `episode.processing_status` to `:error` with a descriptive `processing_error` message — including rate limits, API errors, and unexpected exceptions
- [ ] ERR-003: Rate limit errors from AssemblyAI include actionable guidance in the error message (e.g., "AssemblyAI rate limit exceeded")
- [ ] THR-001: When 10+ `ProcessEpisodeJob`s are enqueued simultaneously, only 3 execute concurrently; the rest block until a slot opens
- [ ] THR-002: The concurrency limit of 3 applies globally across both `ProcessEpisodeJob` and `AutoProcessEpisodeJob` via a shared `"transcription"` key
- [ ] THR-003: While throttled, episodes show `pending` status (not all `transcribing` simultaneously)
- [ ] Episode model has `processing_status` enum with values matching UserEpisode (pending, downloading, transcribing, summarizing, ready, error)
- [ ] Episode model has `processing_error` (text) and `last_error_at` (datetime) columns
- [ ] Existing episodes with both transcript and summary are backfilled to `processing_status: :ready`
- [ ] `UserEpisode#retry_processing!` method resets `processing_status` to `:pending`, clears `retry_count`, `next_retry_at`, and `processing_error`

**Web/API:**
- [ ] Migration: `add_processing_status_to_episodes` — add `processing_status` (integer, default 0, not null), `processing_error` (text), `last_error_at` (datetime) to episodes. Backfill ready status in-migration.
- [ ] Model: `app/models/episode.rb` — add `processing_status` enum
- [ ] Model: `app/models/user_episode.rb` — add `retry_processing!` method
- [ ] Service: `app/services/assembly_ai_client.rb` — rescue `Faraday::TooManyRequestsError` before generic `Faraday::Error`, raise `RateLimitError`
- [ ] Job: `app/jobs/process_episode_job.rb` — add `limits_concurrency key: ->(user_episode_id) { "transcription" }, to: 3`
- [ ] Job: `app/jobs/auto_process_episode_job.rb` — add `limits_concurrency key: ->(episode_id, **) { "transcription" }, to: 3`, add episode-level state tracking (`processing_status`, `processing_error`, `last_error_at` writes)
- [ ] Tests: Job spec for `ProcessEpisodeJob` (new file: `spec/jobs/process_episode_job_spec.rb`) — error handling, state transitions, retry logic, concurrency declaration
- [ ] Tests: Update `spec/jobs/auto_process_episode_job_spec.rb` — episode-level state tracking, error handling, concurrency declaration
- [ ] Tests: Update `spec/models/episode_spec.rb` — processing_status enum
- [ ] Tests: Update `spec/models/user_episode_spec.rb` — retry_processing! method

**iOS:** N/A
**Android:** N/A

**Dependencies:** None (first milestone)

---

### M2: Stuck Job Detection
**What:** Create a recurring job that detects episodes and user_episodes stuck in transitional states (`transcribing`, `summarizing`) and transitions them to `error` with a timeout message.
**Size:** S

**Acceptance Criteria:**
- [ ] ERR-002: UserEpisodes in `transcribing` or `summarizing` state with `updated_at` older than 30 minutes are automatically transitioned to `error` with "Processing timed out" message
- [ ] ERR-002: Episodes in `transcribing` or `summarizing` state with `updated_at` older than 30 minutes are automatically transitioned to `error` with "Processing timed out" message
- [ ] The detection job runs on a recurring schedule (every 10 minutes)
- [ ] The detection job is idempotent — running it multiple times doesn't create duplicate errors or overwrite existing error messages on records already in `error` state

**Web/API:**
- [ ] Job: Create `app/jobs/detect_stuck_processing_job.rb` — queries both `user_episodes` and `episodes` for stuck records, transitions to error
- [ ] Config: `config/recurring.yml` — add `detect_stuck_processing` entry (every 10 minutes, both production and development)
- [ ] Tests: `spec/jobs/detect_stuck_processing_job_spec.rb` — stuck detection for both tables, threshold boundary, idempotency, ignores records already in error state

**iOS:** N/A
**Android:** N/A

**Dependencies:** M1 (needs episode-level `processing_status` column)

---

### M3: Inbox Tab — Processing Status & Retry
**What:** Add processing status indicators, error messages, and retry button to the Inbox tab. Add the `retry_processing` controller action and route.
**Size:** M

**Acceptance Criteria:**
- [ ] INB-001: The Inbox tab displays `processing_status` for each episode — pending (yellow), transcribing (yellow), summarizing (yellow), ready (green), error (red with error message)
- [ ] INB-002: Episodes in `error` state in the Inbox show the error reason text and a "Retry" button
- [ ] INB-003: Clicking "Retry" in the Inbox resets `processing_status` to `:pending`, clears error fields, enqueues `ProcessEpisodeJob`, and redirects to Inbox with notice
- [ ] INB-004: The "Add to Library" action works on errored episodes — moves to Library preserving error state and retry capability

**Web/API:**
- [ ] Controller: `app/controllers/inbox_controller.rb` — add `retry_processing` action (find by current_user, call `retry_processing!`, enqueue `ProcessEpisodeJob`, redirect)
- [ ] Routes: `config/routes.rb` — add `post :retry_processing` to inbox collection routes
- [ ] View: `app/views/inbox/index.html.erb` — add processing status display (case statement matching library pattern), add retry button for error state
- [ ] Tests: `spec/requests/inbox_spec.rb` — retry_processing action (happy path, scoping to current_user, error state reset, job enqueue)

**iOS:** N/A
**Android:** N/A

**Dependencies:** M1 (needs `retry_processing!` method and error handling fixes)

---

### M4: Library Tab — Enhanced Error Display & Retry
**What:** Enhance Library index to show error messages and retry button. Rewire Library show Retry button from `regenerate` to `retry_processing`.
**Size:** S

**Acceptance Criteria:**
- [ ] LIB-001: The Library index shows error message text (not just "Error") for episodes in `error` state
- [ ] LIB-001: A "Retry" button is available on the Library index for error-state episodes
- [ ] LIB-002: The retry count is visible alongside the error message (e.g., "Failed: rate limit exceeded (attempt 3)")
- [ ] Library show page Retry button uses `retry_processing` action instead of `regenerate`
- [ ] The existing `regenerate` action continues to work for ready episodes (re-summarization)

**Web/API:**
- [ ] Controller: `app/controllers/library_controller.rb` — add `retry_processing` action (find by current_user, call `retry_processing!`, enqueue `ProcessEpisodeJob`, redirect back)
- [ ] Routes: `config/routes.rb` — add `post :retry_processing` to library member routes
- [ ] View: `app/views/library/index.html.erb` — enhance error case with `processing_error` message, retry count, and retry button
- [ ] View: `app/views/library/show.html.erb` — rewire error-state Retry button from `regenerate_library_path` to `retry_processing_library_path`
- [ ] Tests: `spec/requests/library_spec.rb` — retry_processing action (happy path, scoping, state reset, job enqueue)

**iOS:** N/A
**Android:** N/A

**Dependencies:** M1 (needs `retry_processing!` method), M3 (shared route pattern)

---

### M5: QA Test Data
**What:** Create a rake task that seeds realistic test data covering all feature scenarios — stuck episodes, errored episodes, throttled processing, various states across Inbox and Library.
**Size:** S

**Acceptance Criteria:**
- [ ] Seed task exists at `lib/tasks/seed_transcription_resilience.rake`
- [ ] Task creates a test user with episodes in various states: pending, transcribing, summarizing, ready, error (with error messages), stuck (transcribing with old updated_at)
- [ ] Task creates episodes in both Inbox and Library locations
- [ ] Task creates episodes with retry history (retry_count > 0, processing_error set)
- [ ] Task is idempotent (can re-run without duplicating data)
- [ ] Task prints a summary of what was created (user email, episode counts per state)
- [ ] All scenarios from manual QA can be tested with the seeded data

**Web/API:**
- [ ] Rake task: `lib/tasks/seed_transcription_resilience.rake` — namespace `seed:transcription_resilience`
- [ ] Uses ActiveRecord directly (not FactoryBot)
- [ ] Creates test podcast, episodes, user_episodes in various states
- [ ] Creates at least one "stuck" episode (transcribing, updated_at 1 hour ago) for testing DetectStuckProcessingJob

**iOS:** N/A
**Android:** N/A

**Dependencies:** M1, M2, M3, M4 (needs full feature implemented)

---

### M6: Edge Cases & Polish
**What:** Handle remaining edge cases, ensure consistency between Inbox and Library, verify idempotency of retry.
**Size:** S

**Acceptance Criteria:**
- [ ] Concurrent retry attempts on the same episode are idempotent — clicking Retry twice doesn't enqueue duplicate jobs (ProcessEpisodeJob checks current state before processing)
- [ ] Episode transcript already exists from another user → ProcessEpisodeJob skips transcription, proceeds to summarization
- [ ] Feed fetch creates episode for multiple subscribers → AutoProcessEpisodeJob runs at episode level, one transcription serves all
- [ ] User clicks Retry while AssemblyAI is still rate-limited → job re-enqueues, may fail again, user sees updated error with incremented retry count
- [ ] Multiple episodes fail simultaneously → all show individual error states with retry buttons in both Inbox and Library
- [ ] Error state styling is visually distinct from in-progress states (red/warning vs yellow/neutral)

**Web/API:**
- [ ] Verify retry idempotency — `ProcessEpisodeJob` already checks `episode.transcript.present?` before calling AssemblyAI; confirm this prevents duplicate API calls
- [ ] Verify `InboxController#add_to_library` preserves error state when moving errored episode (existing `move_to_library!` resets `processing_status` to `:pending` — this is intentional: moving to library re-enqueues processing)
- [ ] Tests: Edge case specs for concurrent retry, shared transcript skip, error display consistency

**iOS:** N/A
**Android:** N/A

**Dependencies:** M3, M4 (needs UI complete for visual verification)

---

## 4. Non-Functional Requirements Checklist

### Data Model & API
> These were reviewed and approved in the Architecture Review checkpoint.

- [x] Architecture proposal approved: `~/projects/show-notes/pipeline-projects/tweak-transcribe-ux/architecture-proposal.md`
- [ ] Milestones correctly reference the approved data model and API design
- [ ] No contradictions between gameplan and approved architecture

### Security & Access Control
- [x] All queries scoped to `current_user.user_episodes` (Inbox and Library controllers)
- [x] Controller authorization via session auth (ApplicationController)
- [ ] Retry actions scoped to own episodes — `current_user.user_episodes.find(params[:id])` raises RecordNotFound for other users
- [x] DetectStuckProcessingJob is unscoped (system job, appropriate)
- [x] No new attack surfaces — retry spam mitigated by Solid Queue concurrency limit
- [ ] N/A — no API authentication (web-only)

### Performance
- [x] Data volume is small (~500 episodes) — no performance concerns
- [x] Stuck-job detection query scans `user_episodes` and `episodes` by `processing_status` + `updated_at` — acceptable at current scale
- [ ] No index needed on `processing_status` at current scale
- [x] Caching needed? No
- [x] N+1 risks: Inbox view already uses `.includes(episode: :podcast)` — no new N+1 introduced

### Observability & Debuggability
- [ ] AutoProcessEpisodeJob logs errors to Rails.logger (existing pattern, now with episode-level state tracking)
- [ ] ProcessEpisodeJob writes error details to `user_episode.processing_error` — visible in Library show page retry debug info panel
- [x] Debug path exists without production access — error messages visible in UI, retry debug info on library show page
- [ ] Alerts needed? No — manual monitoring via admin dashboard (future project)

### Analytics & Instrumentation

#### Success Metrics
- [ ] Zero episodes stuck in `transcribing` for >1 hour with no resolution path
- [ ] Bulk OPML import (100+ podcasts) completes without rate limit failures
- [ ] Zero user-reported "stuck transcription" issues within 30 days

#### Events to Track
_Show Notes has no event tracking infrastructure yet. Skip events table._

#### Instrumentation Approach
- [ ] Framework: None — no tracking infrastructure yet
- [ ] Monitoring via DetectStuckProcessingJob (it logs when it transitions stuck episodes)

### Testing Plan

| Type | Coverage | Platform | Owner |
|------|----------|----------|-------|
| Job specs | ProcessEpisodeJob: error handling, state transitions, retry, concurrency. AutoProcessEpisodeJob: episode-level state tracking. DetectStuckProcessingJob: stuck detection, idempotency. | Rails | Pipeline |
| Model specs | Episode: processing_status enum. UserEpisode: retry_processing! method. | Rails | Pipeline |
| Request specs | Inbox: retry_processing action. Library: retry_processing action. | Rails | Pipeline |
| Manual QA | All user flows (OPML import throttling, Inbox error/retry, Library error/retry, stuck detection recovery) | Web | Human |

### Feature Flags & Rollout
- [x] No feature flag — ship directly (resilience fix, not new feature)
- [x] Single-phase rollout to all users

### Mobile-Specific
- N/A — Level 2 (web-only) project

### Legacy & Migration
- [ ] Backfill existing episodes with transcript + summary to `processing_status: :ready` (in migration)
- [ ] Rake task to transition currently-stuck user_episodes to `error` state (part of M5 seed task or run manually)
- [x] No backwards compatibility concerns — web-only, no API consumers

### Export/Reporting
- N/A — no exports affected

---

## 5. Dependencies & Risks

| Risk/Dependency | Impact | Mitigation |
|-----------------|--------|------------|
| AssemblyAI SDK internal retry behavior | Low | SDK has optional `max_retries` param (currently not set). Our app-level retry handles this. No conflict. |
| Solid Queue concurrency controls are version-dependent | Low | Using `solid_queue-1.3.1` which has `limits_concurrency`. Verified in gem source. |
| Stuck job threshold too aggressive (30 min) | Low | Very long episodes (3+ hours) take ~15 min to transcribe. 30 min is 2x margin. Can increase if needed. |
| `move_to_library!` resets processing_status to `:pending` | Med | This is intentional behavior — moving an errored episode to library re-enqueues processing. Document this in edge case tests so future developers don't misunderstand. |

---

## 6. Release Plan

### Phases

| Phase | What Ships | Flag State | Audience |
|-------|-----------|------------|----------|
| Phase 1 | All milestones (M1-M6) | No flag — direct ship | All users |

### Done Criteria
- [ ] All acceptance criteria met
- [ ] All tests passing (`bundle exec rspec`)
- [ ] Rubocop clean (`bin/rubocop -A`)
- [ ] Brakeman clean (`bin/brakeman --quiet --no-pager`)
- [ ] Seed task produces realistic test data
- [ ] Manual QA walkthrough of all three user flows (OPML import, Inbox error/retry, stuck detection)

---

## 7. Estimates

| Milestone | Size | Notes |
|-----------|------|-------|
| M0: Discovery & Alignment | Done | Pipeline Stages 0-2 |
| M1: Data Model & Core Error Handling | M | Migration + 2 job rewrites + new job spec + service fix |
| M2: Stuck Job Detection | S | 1 new job + recurring config + spec |
| M3: Inbox Tab — Processing Status & Retry | M | Controller action + route + view changes + spec |
| M4: Library Tab — Enhanced Error Display & Retry | S | Controller action + route + 2 view updates + spec |
| M5: QA Test Data | S | 1 rake task |
| M6: Edge Cases & Polish | S | Edge case specs + visual verification |

**Size guide:** S = 1-3 files, no migrations, no new patterns. M = 5-10 files, simple migration, follows existing conventions.

---

## PRD Traceability Matrix

| PRD ID | Requirement | Milestone | Acceptance Criterion |
|--------|------------|-----------|---------------------|
| ERR-001 | Both jobs catch all exceptions and transition to error | M1 | ERR-001 criteria (2 items — ProcessEpisodeJob and AutoProcessEpisodeJob) |
| ERR-002 | Stuck job timeout detection | M2 | ERR-002 criteria (UserEpisode + Episode) |
| ERR-003 | Rate limit error includes actionable guidance | M1 | ERR-003 criterion |
| THR-001 | Throttle concurrent transcription jobs | M1 | THR-001 criterion |
| THR-002 | Throttling works for both job types | M1 | THR-002 criterion |
| THR-003 | Clear feedback during throttled processing | M1 | THR-003 criterion |
| INB-001 | Inbox displays processing_status | M3 | INB-001 criterion |
| INB-002 | Inbox error state shows error reason + Retry | M3 | INB-002 criterion |
| INB-003 | Inbox Retry re-enqueues and resets to pending | M3 | INB-003 criterion |
| INB-004 | Add to Library works on errored episodes | M3 | INB-004 criterion |
| LIB-001 | Library error display with retry | M4 | LIB-001 criteria (2 items) |
| LIB-002 | Failure count visible | M4 | LIB-002 criterion |

---

## Approval Checklist

> **This gameplan requires human review and approval before test generation begins.**

### Reviewer: Dave
### Date: 2/10/2026
### Status: Approved

#### Must Verify
- [x] Milestone breakdown is logical and correctly sequenced
- [x] Acceptance criteria are specific and testable
- [x] Every PRD requirement ID is mapped to a milestone (traceability matrix complete)
- [x] Non-functional requirements checklist is fully addressed
- [x] Dependencies form a valid DAG (no circular dependencies)
- [x] Milestone sizes are appropriate (no XL milestones that should be split)
- [x] Release plan is appropriate

#### Optional Notes
[Any modifications, corrections, or additional context for the implementation team]

---

## Changelog

| Date | Author | Changes |
|------|--------|---------|
| 2026-02-10 | Pipeline | Initial gameplan generated |
