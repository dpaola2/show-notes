# OPML Import - Architecture Proposal

> **Generated by:** Pipeline Stage 2 (Architecture)
> **Date:** 2026-02-07
> **PRD:** `opml-import/prd.md`
> **Discovery Report:** `opml-import/discovery-report.md`

---

## 1. Data Model Changes

### Modified Tables

```sql
-- Add uniqueness index on podcasts.feed_url for OPML dedup
-- No column changes — feed_url already exists
CREATE UNIQUE INDEX index_podcasts_on_feed_url ON podcasts (feed_url);
```

**Rationale:** The `feed_url` column already exists but has no uniqueness constraint. OPML files identify podcasts by feed URL, not by Podcast Index API ID (which is what `guid` currently stores). Adding a uniqueness index on `feed_url` allows `Podcast.find_or_create_by!(feed_url:)` to work reliably for both the existing subscribe-via-search path and the new OPML import path. This is the simplest dedup strategy — see Alternatives Considered for other approaches.

**Data migration note:** Before adding the unique index, we must verify no duplicate `feed_url` values exist. In practice, the existing search-subscribe path creates podcasts via `find_or_create_by!(guid:)`, so duplicates are unlikely but should be checked.

### New Tables

None. The OPML import feature uses existing tables (`podcasts`, `subscriptions`, `episodes`, `user_episodes`). No new persistence is needed because:
- The PRD specifies no mid-flow state persistence (re-upload takes 10 seconds)
- Parsed OPML data lives in the controller/form for the duration of the multi-step flow
- Import results are subscriptions and episodes — both already modeled

### Rails Models

No new models. Existing models are sufficient:

```ruby
# No changes to existing model code.
# Podcast, Subscription, Episode, UserEpisode all work as-is.
#
# The import flow creates records through the same associations
# that the existing search-subscribe flow uses:
#   - Podcast.find_or_create_by!(feed_url:) { |p| p.assign_attributes(...) }
#   - current_user.subscriptions.find_or_create_by!(podcast:)
#   - podcast.episodes.find_or_initialize_by(guid:)
#   - current_user.user_episodes.create!(episode:, location: :library)
```

### New Services

```ruby
# app/services/opml_parser.rb
class OpmlParser
  class Error < StandardError; end

  Feed = Struct.new(:title, :feed_url, keyword_init: true)

  # Parses an OPML XML string and returns an array of Feed structs.
  # Flattens nested folder structures. Skips entries without xmlUrl.
  def self.parse(xml_string)
    new(xml_string).parse
  end

  def initialize(xml_string)
    @xml_string = xml_string
  end

  def parse
    doc = Nokogiri::XML(@xml_string)
    raise Error, "Invalid XML" unless doc.errors.empty? || doc.at("opml")

    outlines = doc.xpath("//outline[@xmlUrl]")
    raise Error, "No podcast feeds found" if outlines.empty?

    outlines.map do |outline|
      Feed.new(
        title: outline["text"] || outline["title"],
        feed_url: outline["xmlUrl"]
      )
    end.uniq { |feed| feed.feed_url }
  end
end
```

```ruby
# app/services/opml_import_service.rb
class OpmlImportService
  Result = Struct.new(:subscribed, :skipped, :failed, keyword_init: true)

  # Creates Podcast + Subscription records for each feed.
  # Returns a Result with counts and details.
  #
  # Does NOT fetch episodes or trigger processing.
  # That happens separately for user-selected favorites.
  def self.subscribe_all(user, feeds)
    new(user, feeds).subscribe_all
  end

  # Fetches the latest episode for each selected podcast,
  # creates UserEpisode in library state, enqueues processing.
  def self.process_favorites(user, podcast_ids)
    new(user, []).process_favorites(podcast_ids)
  end

  private

  def initialize(user, feeds)
    @user = user
    @feeds = feeds
  end

  def subscribe_all
    subscribed = []
    skipped = []
    failed = []

    @feeds.each do |feed|
      podcast = Podcast.find_or_create_by!(feed_url: feed.feed_url) do |p|
        p.guid = feed.feed_url  # Use feed_url as guid for OPML-imported podcasts
        p.title = feed.title || "Unknown Podcast"
      end

      subscription = @user.subscriptions.find_or_initialize_by(podcast: podcast)
      if subscription.new_record?
        subscription.save!
        subscribed << podcast
      else
        skipped << podcast
      end
    rescue => e
      failed << { feed: feed, error: e.message }
    end

    Result.new(subscribed: subscribed, skipped: skipped, failed: failed)
  end

  def process_favorites(podcast_ids)
    podcasts = @user.podcasts.where(id: podcast_ids)

    podcasts.each do |podcast|
      # Fetch the RSS feed to get the latest episode
      episodes = PodcastFeedParser.parse(podcast.feed_url)
      latest = episodes.first
      next unless latest

      # Create or find the episode record
      episode = podcast.episodes.find_or_initialize_by(guid: latest.guid)
      if episode.new_record?
        episode.assign_attributes(
          title: latest.title,
          description: latest.description,
          audio_url: latest.audio_url,
          duration_seconds: latest.duration_seconds,
          published_at: latest.published_at
        )
        episode.save!
      end

      # Create UserEpisode in library (skip inbox) and enqueue processing
      user_episode = @user.user_episodes.find_or_initialize_by(episode: episode)
      if user_episode.new_record?
        user_episode.location = :library
        user_episode.processing_status = :pending
        user_episode.save!
        ProcessEpisodeJob.perform_later(user_episode.id)
      elsif !user_episode.library? || !user_episode.ready?
        # Already exists but not processed — move to library and process
        user_episode.move_to_library!
        ProcessEpisodeJob.perform_later(user_episode.id)
      end
      # If already in library and ready, skip — already processed
    rescue PodcastFeedParser::Error => e
      Rails.logger.warn("[OpmlImportService] Failed to fetch feed for #{podcast.title}: #{e.message}")
      # Continue with remaining podcasts — don't block import
    end
  end
end
```

### Associations Map

```
User 1──* Subscription *──1 Podcast 1──* Episode
  │                                         │
  └──────────* UserEpisode *────────────────┘
              (location, processing_status)

No new associations. Import uses existing relationships.
OPML file → OpmlParser → Feed structs (transient)
Feed structs → OpmlImportService → Podcast + Subscription records
Selected favorites → OpmlImportService → Episode + UserEpisode + ProcessEpisodeJob
```

### Migration Plan

| Migration | Type | Notes |
|-----------|------|-------|
| Add unique index on `podcasts.feed_url` | DDL | Standard `add_index`. Check for existing duplicates first. If any exist, deduplicate before migrating. |

### Expected Data Volumes

| Table | Expected Records per Import | Notes |
|-------|---------------------------|-------|
| podcasts | 15-30 new (or found existing) | One per OPML feed entry |
| subscriptions | 15-30 new (minus already-subscribed) | One per imported podcast |
| episodes | 5-10 new | Only latest episode from favorites |
| user_episodes | 5-10 new | Only for favorite episodes |

Growth is negligible — this is a one-time onboarding flow, not a recurring operation.

---

## 2. API Endpoints

N/A — Level 2 (web-only) project. No API endpoints are created or modified.

The import flow is entirely server-rendered with standard Rails controller actions and form submissions.

---

## 3. Controller Design

Since this is a web-only feature with no API, the controller design replaces the API Endpoints section.

### New Controller: `ImportsController`

```ruby
# app/controllers/imports_controller.rb
class ImportsController < ApplicationController
  # GET /import
  # Shows the upload form (Step 1)
  def new
  end

  # POST /import
  # Parses the uploaded OPML file, subscribes to all feeds,
  # renders the favorites selection form (Step 2)
  def create
    file = params[:opml_file]
    unless file.present?
      redirect_to new_import_path, alert: "Please select a file to upload"
      return
    end

    xml = file.read
    @feeds = OpmlParser.parse(xml)

    # Subscribe to all feeds immediately
    @result = OpmlImportService.subscribe_all(current_user, @feeds)

    # Build list for favorites selection (newly subscribed + already subscribed)
    @podcasts = current_user.podcasts
      .where(feed_url: @feeds.map(&:feed_url))
      .order(:title)

    render :select_favorites
  rescue OpmlParser::Error => e
    redirect_to new_import_path, alert: e.message
  end

  # POST /import/process
  # Processes selected favorites (Step 3 confirmation)
  def process_favorites
    podcast_ids = params[:podcast_ids] || []
    if podcast_ids.empty?
      redirect_to new_import_path, alert: "Please select at least one podcast"
      return
    end

    OpmlImportService.process_favorites(current_user, podcast_ids)
    redirect_to import_complete_path
  end

  # GET /import/complete
  # Shows the confirmation page (Step 3)
  def complete
  end
end
```

### Routes

```ruby
# config/routes.rb (additions)
resource :import, only: [:new, :create] do
  post :process_favorites, on: :collection
  get :complete, on: :collection
end
```

This generates:
| Method | Path | Action | Purpose |
|--------|------|--------|---------|
| GET | `/import/new` | `imports#new` | Upload form |
| POST | `/import` | `imports#create` | Parse OPML, subscribe, show favorites |
| POST | `/import/process_favorites` | `imports#process_favorites` | Process selected favorites |
| GET | `/import/complete` | `imports#complete` | Confirmation page |

### Views

| View | Purpose |
|------|---------|
| `app/views/imports/new.html.erb` | Upload form with generic instructions |
| `app/views/imports/select_favorites.html.erb` | Podcast grid with checkboxes, cost estimate, confirm button |
| `app/views/imports/complete.html.erb` | "Your first digest arrives tomorrow morning" confirmation |

### Cost Estimate Calculation

The favorites selection page needs to show a cost estimate. This uses existing infrastructure:

```ruby
# In the select_favorites view or a helper:
# For each podcast, fetch duration of latest episode (already in @podcasts via join)
# Sum estimated_cost_cents across selected episodes
# Display with existing format_cost_cents helper
```

**Challenge:** At the favorites selection step, we've subscribed to feeds but haven't fetched episodes yet (that happens only for favorites in `process_favorites`). So we don't have `duration_seconds` for cost estimation.

**Solution:** Fetch the latest episode's duration for all imported podcasts during the `create` action. This is a feed-level fetch, not a per-episode processing operation. Store the duration estimate in a hidden field or data attribute on each podcast card.

**Revised flow for `create` action:**
1. Parse OPML → extract feeds
2. Subscribe to all feeds
3. For each podcast, fetch the RSS feed to get the latest episode's duration (for cost estimate)
4. Render favorites selection with cost data

This adds latency (25-30 HTTP requests during the create action). See Open Questions for alternatives.

---

## 4. Backwards Compatibility

### Compatibility Matrix

| Feature / Behavior | Web (current) |
|-------------------|:---:|
| Existing search-subscribe flow | No change — continues to work |
| Existing subscriptions list | Shows OPML-imported subscriptions alongside search-subscribed ones |
| Existing inbox | New episodes from imported feeds appear normally |
| Existing digest email | Includes processed episodes from OPML favorites |
| Existing feed refresh | Polls all subscribed feeds including OPML-imported ones |

### Impact on Existing Podcast Records

Adding a unique index on `feed_url` could theoretically cause issues if:
1. Two existing Podcast records share the same `feed_url` (unlikely but must verify before migration)
2. A Podcast record has a NULL `feed_url` (impossible — `feed_url` has a presence validation)

**Pre-migration check:** Run `Podcast.group(:feed_url).having("count(*) > 1").count` to verify no duplicates exist.

### Podcast GUID Coexistence

After this change, podcasts will have two kinds of `guid` values:
- **Search-subscribed podcasts:** `guid` = Podcast Index API numeric ID (e.g., `"12345"`)
- **OPML-imported podcasts:** `guid` = feed URL (e.g., `"https://example.com/feed.xml"`)

This is fine because:
- `guid` is only used for `find_or_create_by!(guid:)` in the search-subscribe path
- The OPML import path uses `find_or_create_by!(feed_url:)` instead
- Both paths produce valid, unique Podcast records
- If the same podcast is subscribed via search AND imported via OPML, the `feed_url` uniqueness index ensures only one record exists (the OPML import finds the existing record by feed_url)

**Edge case:** If a user first subscribes via search (creating a Podcast with `guid` = API ID), then imports OPML containing the same feed URL, `find_or_create_by!(feed_url:)` finds the existing record. No duplicate. The `guid` remains the API ID. This is correct behavior.

### API Versioning

N/A — no API changes.

---

## 5. Security Design

### Query Scoping

| Resource | Scoping Chain |
|----------|--------------|
| Subscriptions (read) | `current_user.subscriptions` |
| Subscriptions (create) | `current_user.subscriptions.find_or_create_by!(podcast:)` |
| Podcasts (for favorites) | `current_user.podcasts.where(id: podcast_ids)` |
| UserEpisodes (create) | `current_user.user_episodes.find_or_initialize_by(episode:)` |

All data access is scoped to `current_user`. No cross-user data leakage possible.

### Authorization

| Action | Permitted Users | Check |
|--------|----------------|-------|
| View import page | Any authenticated user | `before_action :require_authentication` (from ApplicationController) |
| Upload OPML | Any authenticated user | Same |
| Select favorites | Any authenticated user | Same — podcasts scoped to current_user |
| Process favorites | Any authenticated user | Same — podcast_ids validated against current_user.podcasts |

### New Attack Surface

| Vector | Risk | Mitigation |
|--------|------|------------|
| **Malicious XML upload (XXE)** | Med | Nokogiri disables external entities by default (`NOENT` is not set). Standard Rails file upload handling. |
| **Very large file upload** | Low | Rails default upload limit. Additionally, reject files > 1MB in controller (OPML files are typically < 100KB). |
| **Malicious feed URLs in OPML** | Low | Feed URLs are stored but not fetched until the user selects favorites. `PodcastFeedParser` handles network errors gracefully. No server-side request forgery risk beyond what already exists in the search-subscribe path. |
| **Excessive processing cost** | Low | User sees cost estimate before confirming. Same trust model as the existing "Add to Library" button. |

---

## 6. Export Impact

| Export | Format | Changes | Backwards Compatible? |
|-------|--------|---------|----------------------|
| Daily Digest Email | HTML email | No changes — digest automatically includes processed episodes from any source | Yes |

No new exports. No impact on existing exports.

---

## 7. Open Questions for Human Review

| # | Question | Options | Recommendation |
|---|----------|---------|---------------|
| 1 | **Feed fetching for cost estimates adds latency to the create action.** Fetching 25-30 RSS feeds during the POST takes 10-30 seconds. | A: Fetch all feeds synchronously in the create action (simple, slow) / B: Skip cost estimates on the selection page, show only after favorites are selected via AJAX / C: Show cost estimates as "calculating..." and fetch via background jobs + Turbo Streams / D: Use a flat per-episode estimate (~$0.46) without fetching actual durations | **D** — Use a flat estimate. The PRD's framing doc already uses ~$0.46/episode as the cost basis. Showing "$0.46 × 7 episodes ≈ $3.22" is transparent and avoids all the latency/complexity of fetching 25 feeds just for duration data. If cost accuracy matters more later, upgrade to option B. |
| 2 | **Should the import page be accessible when the user already has subscriptions, or only in the empty state?** The PRD says dashboard empty state is the primary CTA and Settings is the secondary. But should `/import/new` be accessible directly via URL even if subscriptions exist? | A: Always accessible via URL and Settings link (re-import allowed per PRD) / B: Only accessible when user has zero subscriptions | **A** — Always accessible. The PRD explicitly allows re-import (skip duplicates). Blocking access when subscriptions exist would prevent importing from a second podcast app. |
| 3 | **Should artwork be fetched from the RSS feed for each imported podcast?** OPML files don't contain artwork URLs. Getting artwork requires fetching each RSS feed to read the `<itunes:image>` tag. | A: No artwork — show podcast title only in favorites selection (fast, simple) / B: Fetch artwork from RSS feeds during the create action (adds same latency as Q1) / C: Show artwork only for podcasts that already exist in the database (previously subscribed via search — they already have artwork_url) | **C** — Show artwork for existing podcasts (they already have it from Podcast Index), show a placeholder for new ones. This adds zero latency and handles the common re-import case nicely. Artwork for new podcasts can be backfilled when their feeds are first fetched by RefreshAllFeedsJob. |

---

## 8. Alternatives Considered

### Alternative 1: Look Up OPML Feeds via Podcast Index API

**Description:** For each feed URL in the OPML, call `PodcastIndexClient` to look up the podcast by feed URL and get the canonical Podcast Index ID. Use that ID as the `guid`, maintaining consistency with the search-subscribe path.

**Pros:**
- All podcasts have the same guid format (Podcast Index numeric ID)
- Artwork, author, description all come from the API
- No guid coexistence issue

**Cons:**
- 25-30 API calls during import (latency, rate limit risk)
- Podcast Index API may not have every podcast (smaller/indie feeds)
- Adds external dependency to the import flow (API downtime blocks import)
- Podcast Index has rate limits that could block large imports

**Why rejected:** The feed URL is the canonical identifier — it's what OPML files contain, and it's what `FetchPodcastFeedJob` uses to actually fetch content. Adding an API dependency for a cosmetic concern (guid consistency) adds fragility for no user-facing benefit.

### Alternative 2: Normalize All Podcast GUIDs to Feed URL

**Description:** Migrate all existing Podcast records to use `feed_url` as `guid`. Run a data migration to update `guid = feed_url` for all existing records.

**Pros:**
- Single, consistent guid strategy
- Simplifies all future lookup code

**Cons:**
- Data migration on a live table
- Any code that relies on `guid` being the Podcast Index ID would break
- `PodcastsController#find_or_create_podcast` would need to change
- Risk of breaking existing data integrity if any external references use the current guid

**Why rejected:** Unnecessary risk for a marginal consistency benefit. The two guid formats can coexist — they're unique per-record and don't conflict. The `feed_url` uniqueness index handles dedup.

### Alternative 3: Multi-Step Wizard with Turbo Frames

**Description:** Build the import as a single-page wizard using Turbo Frames, where each step replaces a frame within the page without full-page navigation.

**Pros:**
- Smoother UX (no full-page reloads between steps)
- Can progressively load data (e.g., artwork) via lazy Turbo Frames

**Cons:**
- More complex than standard Rails form submission
- The import flow is 3 steps that a user does once — wizard smoothness adds little value
- Turbo Frames add complexity to error handling (how to show flash messages within frames)

**Why rejected:** YAGNI. Standard Rails controller actions with redirects are simpler, more testable, and sufficient for a 3-step flow that users do once. The PRD says "5 minutes" — full-page loads add maybe 2 seconds total.

---

## 9. Summary

### Files to Create

| File | Purpose |
|------|---------|
| `app/services/opml_parser.rb` | Parses OPML XML → array of Feed structs |
| `app/services/opml_import_service.rb` | Creates subscriptions, processes favorites |
| `app/controllers/imports_controller.rb` | Multi-step import flow (upload → select → confirm) |
| `app/views/imports/new.html.erb` | Upload form with generic instructions |
| `app/views/imports/select_favorites.html.erb` | Podcast grid with checkboxes and cost estimate |
| `app/views/imports/complete.html.erb` | Confirmation page |
| `db/migrate/XXXXXX_add_unique_index_to_podcasts_feed_url.rb` | Uniqueness constraint on feed_url |
| `spec/services/opml_parser_spec.rb` | OPML parsing tests |
| `spec/services/opml_import_service_spec.rb` | Import service tests |
| `spec/requests/imports_spec.rb` | Request specs for import flow |

### Files to Modify

| File | Changes |
|------|---------|
| `config/routes.rb` | Add `resource :import` routes |
| `app/views/inbox/index.html.erb` | Add "Import your podcasts" CTA in empty state |
| `app/views/settings/show.html.erb` | Add "Import Podcasts" section with link |

---

## Approval Checklist

> **This architecture proposal requires human review and approval before the gameplan is generated.**

### Reviewer: Dave
### Date: 2/7/2026
### Status: Accepted

#### Must Verify
- [x] Data model is architecturally sound (unique index on feed_url, guid coexistence strategy)
- [x] Controller design follows existing patterns (standard Rails actions, no over-engineering)
- [x] Backwards compatibility is handled correctly (existing subscribe path unaffected)
- [x] Security scoping is correct (all queries scoped to current_user)
- [x] Migration strategy is safe (check for duplicate feed_urls before adding unique index)

#### Should Check
- [x] Service design matches existing patterns (OpmlParser follows PodcastFeedParser style)
- [x] Export impact is addressed (digest email automatically includes new content)
- [x] Open questions are answerable (flat cost estimate, always-accessible import, artwork strategy)
- [x] No conflicts with in-progress work or upcoming changes

#### Notes
[Reviewer notes, modifications requested, or rejection reasons]
