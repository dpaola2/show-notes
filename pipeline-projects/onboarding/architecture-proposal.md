# Phase 2 Onboarding — Architecture Proposal

> **Generated by:** Pipeline Stage 2 (Architecture)
> **Date:** 2026-02-07
> **PRD:** `onboarding/prd.md`
> **Discovery Report:** `onboarding/discovery-report.md`

---

## 1. Data Model Changes

### New Tables

#### `email_events`

Tracks email opens and link clicks from digest emails. Each row represents a single engagement event.

```ruby
create_table "email_events" do |t|
  t.bigint "user_id", null: false           # FK to users
  t.string "token", null: false              # Opaque token for URL (SecureRandom.urlsafe_base64)
  t.string "event_type", null: false         # "open" or "click"
  t.string "link_type"                       # "summary" or "listen" (null for opens)
  t.bigint "episode_id"                      # FK to episodes (null for opens)
  t.datetime "triggered_at"                  # When the user opened/clicked (null = not yet triggered)
  t.string "digest_date", null: false        # Date string "2026-02-07" — which digest this belongs to
  t.string "user_agent"                      # From request headers when triggered
  t.timestamps
end

add_index :email_events, :token, unique: true
add_index :email_events, [:user_id, :digest_date]
add_index :email_events, [:episode_id, :event_type]
add_foreign_key :email_events, :users
add_foreign_key :email_events, :episodes
```

**Design rationale:** One `email_events` table for both opens and clicks (vs separate tables) keeps the schema simple and queryable. The `token` column is the key for URLs — `/t/:token` resolves to an event, records the trigger, and redirects to the destination. Open events have a pre-created row per digest; click events have a pre-created row per episode per link type per digest.

### Modified Tables

No changes to existing tables.

### Rails Models

```ruby
# app/models/email_event.rb
class EmailEvent < ApplicationRecord
  belongs_to :user
  belongs_to :episode, optional: true  # null for open events

  validates :token, presence: true, uniqueness: true
  validates :event_type, presence: true, inclusion: { in: %w[open click] }
  validates :link_type, inclusion: { in: %w[summary listen] }, allow_nil: true
  validates :digest_date, presence: true

  scope :opens, -> { where(event_type: "open") }
  scope :clicks, -> { where(event_type: "click") }
  scope :triggered, -> { where.not(triggered_at: nil) }
  scope :for_date, ->(date) { where(digest_date: date.to_s) }

  def triggered?
    triggered_at.present?
  end

  def trigger!(request: nil)
    return if triggered?
    update!(
      triggered_at: Time.current,
      user_agent: request&.user_agent
    )
  end
end
```

```ruby
# Add to app/models/user.rb
class User < ApplicationRecord
  # ... existing associations ...
  has_many :email_events, dependent: :destroy
end

# Add to app/models/episode.rb
class Episode < ApplicationRecord
  # ... existing associations ...
  has_many :email_events, dependent: :destroy

  scope :with_summary, -> { joins(:summary) }
  scope :published_after, ->(time) { where("episodes.published_at > ?", time) }
end
```

### Associations Map

```
User 1──* Subscription *──1 Podcast 1──* Episode
  │                                         │
  │                                    1──0..1 Summary
  │                                    1──0..1 Transcript
  │                                         │
  └──* EmailEvent *──0..1 Episode            │
  └──* UserEpisode *──1 Episode  ────────────┘
```

**Key relationships for the new digest:**
- Digest query path: `User → Subscription → Podcast → Episode → Summary`
- Tracking: `User → EmailEvent → Episode`
- Episode detail: `Episode → Summary + Transcript` (new route, no UserEpisode required)

### Expected Data Volumes

| Table | Expected Records | Access Frequency | Growth Rate |
|-------|-----------------|------------------|-------------|
| email_events | ~100/user/day (1 open + ~50 episodes × 2 links) | Write: batch on digest send. Read: on each open/click + admin queries. | ~3,000/user/month |

At 3 test users for 1 week, this is ~2,100 rows total. Negligible.

---

## 2. API Endpoints

### New Routes (Web, not API)

This is a web-only application with no external API. The new routes serve HTML pages and tracking responses.

#### GET `/episodes/:id`

**Purpose:** Show episode detail page with summary and audio player. Accessible to any authenticated user who is subscribed to the episode's podcast. This is the destination for digest "Read full summary" and "Listen" links.

**Authorization:** Authenticated user must have a subscription to the episode's podcast.

**Scoping:**
```ruby
# EpisodesController#show
episode = Episode.find(params[:id])
unless current_user.podcasts.exists?(id: episode.podcast_id)
  redirect_to root_path, alert: "Episode not found"
end
```

**View:** Reuses the same layout as `library/show.html.erb` — summary sections, quotes with timestamps, audio player. Does NOT show "Mark as Done" or "Regenerate Summary" buttons (those are library-specific actions). Shows a "Back to Library" link only if the user has a library UserEpisode for this episode; otherwise shows "Back to Inbox" or no back link.

#### GET `/t/:token`

**Purpose:** Track a click event and redirect to the destination URL. Used for "Read full summary" and "Listen" links in digest emails.

**Authorization:** None — tracking links must work without authentication (email clients, link previews). The token is opaque and unguessable.

**Behavior:**
1. Find `EmailEvent` by token
2. Call `event.trigger!(request: request)`
3. Redirect to destination URL:
   - For `link_type: "summary"` → `episode_path(event.episode)`
   - For `link_type: "listen"` → `episode_path(event.episode, anchor: "audio")`
4. If token not found → redirect to root_path (graceful degradation)

**Controller:**
```ruby
# app/controllers/tracking_controller.rb
class TrackingController < ApplicationController
  skip_before_action :require_authentication

  # GET /t/:token — click tracking redirect
  def click
    event = EmailEvent.find_by(token: params[:token])

    if event
      event.trigger!(request: request)
      redirect_to destination_for(event), allow_other_host: false
    else
      redirect_to root_path
    end
  end

  # GET /t/:token/pixel.gif — open tracking pixel
  def pixel
    event = EmailEvent.find_by(token: params[:token])
    event&.trigger!(request: request)

    send_data TRANSPARENT_GIF, type: "image/gif", disposition: "inline"
  end

  private

  TRANSPARENT_GIF = Base64.decode64(
    "R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"
  ).freeze

  def destination_for(event)
    case event.link_type
    when "summary"
      episode_path(event.episode)
    when "listen"
      episode_path(event.episode, anchor: "audio")
    else
      root_path
    end
  end
end
```

#### GET `/t/:token/pixel.gif`

**Purpose:** Tracking pixel for email open detection. Embedded as an `<img>` tag in the digest HTML.

**Authorization:** None.

**Behavior:**
1. Find `EmailEvent` by token
2. Call `event.trigger!(request: request)` if found
3. Return 1x1 transparent GIF regardless (no error even if token invalid)

### Modified Routes

```ruby
# config/routes.rb additions
resources :episodes, only: [:show]

# Tracking routes (outside authentication)
get "t/:token", to: "tracking#click", as: :tracking_click
get "t/:token/pixel.gif", to: "tracking#pixel", as: :tracking_pixel
```

### Modified Controllers / Jobs

#### `FetchPodcastFeedJob` — Add Auto-Processing Trigger

When a new episode is discovered during feed polling, enqueue processing immediately:

```ruby
# In FetchPodcastFeedJob#perform, after episode.save!:
if episode.new_record?
  episode.save!

  # Create inbox entry for each subscriber (existing behavior)
  subscribers.each do |subscription|
    subscription.user.user_episodes.create!(episode: episode, location: :inbox)
  end

  # AUTO-PROCESS: Enqueue transcription + summarization (new behavior)
  AutoProcessEpisodeJob.perform_later(episode.id)
end
```

#### New: `AutoProcessEpisodeJob`

Processes an episode at the Episode level (not user-scoped). Reuses the same AssemblyAI + Claude pipeline.

```ruby
# app/jobs/auto_process_episode_job.rb
class AutoProcessEpisodeJob < ApplicationJob
  queue_as :default

  MAX_RETRIES = 5
  BASE_DELAY = 60

  def perform(episode_id, retry_count: 0)
    episode = Episode.find(episode_id)

    # Skip if already processed
    return if episode.transcript.present? && episode.summary.present?

    # Step 1: Transcribe
    unless episode.transcript.present?
      transcript = AssemblyAiClient.transcribe(episode.audio_url)
      episode.create_transcript!(content: transcript.to_json)
    end

    # Step 2: Summarize
    unless episode.summary.present?
      summary = ClaudeClient.summarize_chunked(episode.transcript.content)
      episode.create_summary!(
        sections: summary["sections"],
        quotes: summary["quotes"]
      )
    end

  rescue ClaudeClient::RateLimitError, AssemblyAiClient::Error => e
    handle_retryable_error(episode_id, retry_count, e)
  rescue => e
    Rails.logger.error("[AutoProcessEpisodeJob] Episode #{episode_id} failed: #{e.message}")
  end

  private

  def handle_retryable_error(episode_id, retry_count, error)
    new_retry_count = retry_count + 1
    if new_retry_count > MAX_RETRIES
      Rails.logger.error("[AutoProcessEpisodeJob] Episode #{episode_id} exceeded #{MAX_RETRIES} retries: #{error.message}")
      return
    end

    delay_seconds = BASE_DELAY * (2 ** (new_retry_count - 1))
    AutoProcessEpisodeJob.set(wait: delay_seconds.seconds).perform_later(episode_id, retry_count: new_retry_count)
  end
end
```

**Why a new job instead of modifying ProcessEpisodeJob:** `ProcessEpisodeJob` is tightly coupled to `UserEpisode` — it updates `processing_status`, `retry_count`, and `processing_error` on the user's copy. Auto-processing has no user context. A separate job avoids polluting the existing interface and keeps both jobs simple. The transcription/summarization logic is identical — both call `AssemblyAiClient.transcribe` and `ClaudeClient.summarize_chunked` on the Episode.

#### `DigestMailer` — Complete Rewrite of Query and Template

```ruby
# app/mailers/digest_mailer.rb
class DigestMailer < ApplicationMailer
  helper ApplicationHelper

  def daily_digest(user)
    @user = user
    @date = Date.current.strftime("%A, %B %-d")
    @digest_date = Date.current.to_s

    # Query: ALL new episodes from subscribed podcasts since last digest
    since = user.digest_sent_at || 1.day.ago
    @episodes_by_show = Episode
      .joins(podcast: :subscriptions)
      .where(subscriptions: { user_id: user.id })
      .where("episodes.created_at > ?", since)
      .includes(:podcast, :summary)
      .order("podcasts.title ASC, episodes.published_at DESC")
      .group_by(&:podcast)

    @episode_count = @episodes_by_show.values.flatten.size
    return if @episode_count.zero?  # Don't send empty digest

    # Pre-create tracking events
    @open_event = create_tracking_event(user, "open")
    @click_events = {}
    @episodes_by_show.each_value do |episodes|
      episodes.each do |episode|
        @click_events[episode.id] = {
          summary: create_tracking_event(user, "click", episode: episode, link_type: "summary"),
          listen: create_tracking_event(user, "click", episode: episode, link_type: "listen")
        }
      end
    end

    mail(
      to: user.email,
      subject: "Your podcasts this morning — #{@episode_count} new episode#{'s' unless @episode_count == 1}"
    )
  end

  private

  def create_tracking_event(user, event_type, episode: nil, link_type: nil)
    EmailEvent.create!(
      user: user,
      token: SecureRandom.urlsafe_base64(16),
      event_type: event_type,
      link_type: link_type,
      episode: episode,
      digest_date: @digest_date
    )
  end
end
```

#### `SendDailyDigestJob` — Simplified Decision Logic

```ruby
# app/jobs/send_daily_digest_job.rb
class SendDailyDigestJob < ApplicationJob
  queue_as :default

  def perform
    users_to_notify = User.where(digest_enabled: true)
    sent_count = 0
    skipped_count = 0

    users_to_notify.find_each do |user|
      if has_new_episodes?(user)
        DigestMailer.daily_digest(user).deliver_later
        user.update!(digest_sent_at: Time.current)
        sent_count += 1
      else
        skipped_count += 1
      end
    end

    Rails.logger.info("[SendDailyDigestJob] Sent #{sent_count} digests, skipped #{skipped_count}")
  end

  private

  def has_new_episodes?(user)
    since = user.digest_sent_at || 1.day.ago
    Episode
      .joins(podcast: :subscriptions)
      .where(subscriptions: { user_id: user.id })
      .where("episodes.created_at > ?", since)
      .exists?
  end
end
```

#### Backfill Task — One-time Rake Task

```ruby
# lib/tasks/backfill_processing.rake
namespace :onboarding do
  desc "Backfill: auto-process ~10 most recent unprocessed episodes per podcast for all subscribers"
  task backfill_episodes: :environment do
    User.find_each do |user|
      user.podcasts.each do |podcast|
        episodes = podcast.episodes
          .left_joins(:summary)
          .where(summaries: { id: nil })
          .order(published_at: :desc)
          .limit(10)

        episodes.each do |episode|
          next if episode.transcript.present? && episode.summary.present?
          AutoProcessEpisodeJob.perform_later(episode.id)
        end

        puts "  Queued #{episodes.size} episodes for #{podcast.title}"
      end
    end
  end
end
```

### Migration Plan

| # | Migration | Type | Notes |
|---|-----------|------|-------|
| 1 | Create `email_events` table | DDL | Standard `create_table` with indexes |

Single migration. No data migration needed — existing tables are unchanged.

---

## 3. Backwards Compatibility

### Compatibility Matrix

| Feature / Behavior | Web (current) |
|-------------------|:---:|
| Existing inbox/library/archive workflow | No change — continues to work as-is |
| Existing digest email format | **Replaced** — old format superseded by newsletter format |
| Existing digest_enabled setting | No change — still controls opt-in/out |
| Library show page (`/library/:id`) | No change — still works for UserEpisode-based access |
| New episode show page (`/episodes/:id`) | **New** — accessible to subscribers of that podcast |
| Auto-processing | **New** — episodes process automatically on feed poll |
| Tracking links in digest | **New** — old digest had direct links, new has redirect tracking |
| Tracking pixel in digest | **New** — no open tracking existed before |

### Old Client Behavior

N/A — web-only, no mobile clients. All users see the new digest format immediately upon deploy.

### API Versioning

N/A — no API.

### Data Migration

No data migration. New `email_events` table starts empty. Existing episodes are backfilled via rake task (one-time, on-demand).

---

## 4. Security Design

### Query Scoping

| Resource | Scoping Chain |
|----------|--------------|
| Episode show page | `Episode.find(id)` then verify `current_user.podcasts.exists?(id: episode.podcast_id)` — user can only view episodes from podcasts they're subscribed to |
| Digest email content | `Episode.joins(podcast: :subscriptions).where(subscriptions: { user_id: user.id })` — only episodes from user's subscriptions |
| Tracking click redirect | `EmailEvent.find_by(token:)` — opaque token, no user ID in URL. Destination is always an internal path. |
| Tracking pixel | `EmailEvent.find_by(token:)` — opaque token, returns GIF regardless of validity |
| Email events (admin/reporting) | `EmailEvent.where(user_id:)` — scoped to user |

### Authorization

| Action | Permitted Roles | Check |
|--------|----------------|-------|
| View episode | Authenticated user with subscription | `current_user.podcasts.exists?(id: episode.podcast_id)` |
| Receive digest | Users with `digest_enabled: true` | Checked in `SendDailyDigestJob` |
| Click tracking link | Anyone with the token | No auth — token is opaque, unguessable, links to internal pages only |
| Open tracking pixel | Anyone with the token | No auth — returns static GIF |

### New Attack Surface

| Vector | Risk | Mitigation |
|--------|------|------------|
| Open redirect via tracking link | Low | `destination_for(event)` only returns internal `episode_path` or `root_path`. No user-supplied URLs. `allow_other_host: false` on redirect. |
| Token enumeration | Low | Tokens are `SecureRandom.urlsafe_base64(16)` (128 bits of randomness). Infeasible to enumerate. |
| Tracking pixel abuse (bot crawling) | Low | Open events may fire from email client proxies (Gmail, Apple Mail). This is a known limitation of email open tracking, not a security issue. |
| Episode show page leaks data | Low | Subscription check prevents unauthorized access. Episodes only visible to subscribers. |

---

## 5. Export Impact

No existing exports are affected. This feature does not produce PDF, CSV, or Excel exports.

The engagement tracking data (TRK-005) is accessible via a rake task for now:

```ruby
# lib/tasks/engagement_report.rake
namespace :onboarding do
  desc "Report: engagement stats for digest emails"
  task engagement_report: :environment do
    EmailEvent.triggered.group(:digest_date, :event_type, :link_type).count.each do |(date, type, link), count|
      puts "#{date} | #{type.ljust(5)} | #{(link || '-').ljust(8)} | #{count}"
    end
  end
end
```

---

## 6. Open Questions for Human Review

| # | Question | Options | Recommendation |
|---|----------|---------|---------------|
| 1 | Should the new `/episodes/:id` route coexist with the existing `/library/:id` route, or should library links redirect to `/episodes/:id`? | A: Coexist (library show page stays for library-specific actions like archive/regenerate; episodes page is read-only). B: Redirect library show to episodes show and add archive/regenerate buttons conditionally. | **A: Coexist.** Library page has library-specific actions (archive, regenerate). Episode page is a clean read-only view for digest links. Two routes, two purposes. Avoids changing existing library behavior. |
| 2 | For the digest email, should the summary text be the first section's content (from the Summary model), or a separate 2-3 sentence digest-specific summary? | A: Use first section content, truncated to ~200 chars. B: Add a `digest_summary` column to Summary model (generated during summarization). C: Generate a short summary on-the-fly from sections when composing the email. | **A: Use first section content, truncated.** Simplest approach — no model changes, no additional API calls. The first section typically captures the episode's main topic. If quality is poor, can upgrade to B in a later iteration. |
| 3 | When an auto-processed episode still has no summary at digest send time, should it appear in the digest with "Summary processing..." or be omitted? | A: Include with "Summary processing..." note (PRD DIG-008). B: Omit — only show episodes with completed summaries. | **A: Include with note.** Matches PRD requirement DIG-008. User sees the episode exists even if processing isn't complete. The "Read full summary" link still works — it'll show the processing state on the episode page. |

---

## 7. Alternatives Considered

### Alternative: Modify ProcessEpisodeJob to Accept Episode ID

**Description:** Add a second `perform` signature to `ProcessEpisodeJob` that takes `episode_id` instead of `user_episode_id`, sharing the transcription/summarization logic.

**Pros:** Single job class, DRY transcription/summarization code.

**Cons:** `ProcessEpisodeJob` is tightly coupled to `UserEpisode` — it updates `processing_status`, `retry_count`, `processing_error` on the user's copy. Adding a second code path with different error handling makes the job harder to reason about. Two concerns (user-scoped status tracking and episode-level processing) mixed in one class.

**Why rejected:** A separate `AutoProcessEpisodeJob` is cleaner — same external API calls, but error handling is simpler (just log and retry, no user-facing status to update). If the transcription/summarization logic is later extracted into a service object, both jobs can call it.

### Alternative: Create UserEpisodes for Auto-Processed Episodes

**Description:** When auto-processing triggers, create a UserEpisode for every subscriber (in a new "processed" location or reuse "library").

**Pros:** Digest can reuse the existing UserEpisode-based queries. Library show page works without a new route.

**Cons:** Creates many UserEpisode records that the user didn't ask for. A user with 30 podcasts getting 5 episodes/podcast/day = 150 UserEpisode records created daily without user action. Pollutes the existing inbox/library/archive lifecycle. The user's inbox would be overwhelmed.

**Why rejected:** The existing UserEpisode model represents explicit user decisions about episodes (triage → library → archive). Auto-processing is about the episode itself, not the user's relationship to it. The new `/episodes/:id` route cleanly separates "episode that has been processed" from "episode the user is managing."

### Alternative: Tracking via UTM Parameters

**Description:** Append UTM parameters to digest links (e.g., `?utm_source=digest&utm_episode=123`) and parse them on the destination page.

**Pros:** No redirect hop — slightly faster for user. No tracking controller.

**Cons:** Can't track if user doesn't actually visit the page (link previews don't trigger Rails). No server-side record of clicks — depends on the destination page logging the UTM params. Harder to query engagement data (spread across request logs vs a dedicated table).

**Why rejected:** Internal redirect links give us a clean, queryable tracking table (`email_events`) with per-episode granularity. The redirect adds negligible latency (~10ms). Follows the "favor internal control" principle.

---

## 8. Summary

### Files to Create

| File | Purpose |
|------|---------|
| `db/migrate/XXXXXX_create_email_events.rb` | Tracking table for email opens and clicks |
| `app/models/email_event.rb` | EmailEvent model with validations, scopes |
| `app/controllers/episodes_controller.rb` | Episode detail page (read-only, subscription-scoped) |
| `app/controllers/tracking_controller.rb` | Click redirect and open pixel endpoints |
| `app/views/episodes/show.html.erb` | Episode detail view (summary + audio player) |
| `app/jobs/auto_process_episode_job.rb` | Episode-level auto-processing (no UserEpisode) |
| `app/views/digest_mailer/daily_digest.html.erb` | Redesigned newsletter-format HTML template |
| `app/views/digest_mailer/daily_digest.text.erb` | Redesigned plain-text template |
| `lib/tasks/backfill_processing.rake` | One-time backfill of ~10 episodes per podcast |
| `lib/tasks/engagement_report.rake` | Rake task for engagement stats |

### Files to Modify

| File | Changes |
|------|---------|
| `app/models/user.rb` | Add `has_many :email_events` |
| `app/models/episode.rb` | Add `has_many :email_events`, `with_summary` scope, `published_after` scope |
| `app/mailers/digest_mailer.rb` | Complete rewrite — new query path (Subscription→Episode), grouped by show, tracking event creation |
| `app/jobs/send_daily_digest_job.rb` | Simplified decision logic — check for new episodes via Subscription→Episode path |
| `app/jobs/fetch_podcast_feed_job.rb` | Add `AutoProcessEpisodeJob.perform_later(episode.id)` after new episode creation |
| `config/routes.rb` | Add `resources :episodes, only: [:show]`, tracking routes |

### Files Unchanged

| File | Why |
|------|-----|
| `app/jobs/process_episode_job.rb` | Existing user-scoped processing continues to work for manual Library adds |
| `app/controllers/library_controller.rb` | Library workflow unchanged — coexists with new episode route |
| `app/controllers/inbox_controller.rb` | Inbox workflow unchanged |
| `app/models/user_episode.rb` | No changes needed |
| `app/controllers/settings_controller.rb` | `digest_enabled` toggle works as-is |

---

## Approval Checklist

> **This architecture proposal requires human review and approval before the gameplan is generated.**

### Reviewer: Dave
### Date: 2/7/2026
### Status: Accepted

#### Must Verify
- [x] Data model is architecturally sound (email_events table, indexes, foreign keys)
- [x] New routes are consistent with existing patterns (`/episodes/:id`, `/t/:token`)
- [x] Backwards compatibility is handled (old digest replaced, library route unchanged)
- [x] Security scoping is correct (subscription check on episode show, opaque tokens for tracking)
- [x] Migration strategy is safe (single new table, no existing table changes)

#### Should Check
- [x] Auto-processing trigger in FetchPodcastFeedJob is the right place (vs separate scheduled job)
- [x] AutoProcessEpisodeJob as separate job (vs modifying ProcessEpisodeJob) is the right approach
- [x] Digest query path (Subscription → Episode) correctly replaces UserEpisode-based query
- [x] Episode show page coexisting with library show page (vs redirect) is acceptable
- [x] Backfill approach (~10 per podcast via rake task) is the right mechanism
- [x] Engagement reporting via rake task is sufficient (vs admin dashboard)

#### Notes
