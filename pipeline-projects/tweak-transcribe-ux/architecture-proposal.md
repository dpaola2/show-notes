---
pipeline_stage: 2
pipeline_stage_name: architecture
pipeline_project: "tweak-transcribe-ux"
pipeline_started_at: "2026-02-09T21:32:04-0500"
pipeline_completed_at: "2026-02-09T21:32:35-0500"
pipeline_approved_at: "2026-02-10T00:00:00-0500"
---

# Transcription Resilience & Retry UX — Architecture Proposal

> **Generated by:** Pipeline Stage 2 (Architecture)
> **Date:** 2026-02-09
> **PRD:** `~/projects/show-notes/pipeline-projects/tweak-transcribe-ux/prd.md`
> **Discovery Report:** `~/projects/show-notes/pipeline-projects/tweak-transcribe-ux/discovery-report.md`

---

## 1. Data Model Changes

### Modified Tables

```sql
-- Add episode-level processing tracking (for AutoProcessEpisodeJob)
ALTER TABLE episodes
  ADD COLUMN processing_status integer DEFAULT 0 NOT NULL,
  ADD COLUMN processing_error text,
  ADD COLUMN last_error_at datetime;
```

The `processing_status` enum on Episode mirrors the UserEpisode enum values:
- `0` = pending
- `1` = downloading
- `2` = transcribing
- `3` = summarizing
- `4` = ready
- `5` = error

This gives `AutoProcessEpisodeJob` a place to write error state at the episode level.

### No New Tables

No new tables are required. All retry tracking fields already exist on `user_episodes`. The stuck-job detector will be a recurring Solid Queue job using existing tables.

### Rails Models

```ruby
# app/models/episode.rb — add enum and processing state
class Episode < ApplicationRecord
  # ... existing associations and validations ...

  enum :processing_status, {
    pending: 0,
    downloading: 1,
    transcribing: 2,
    summarizing: 3,
    ready: 4,
    error: 5
  }
end
```

```ruby
# app/models/user_episode.rb — add retry method
class UserEpisode < ApplicationRecord
  # ... existing code unchanged ...

  def retry_processing!
    update!(
      processing_status: :pending,
      retry_count: 0,
      next_retry_at: nil,
      processing_error: nil
    )
  end
end
```

### Associations Map

```
Podcast 1──* Episode 1──1 Transcript
                │    └──1 Summary
                │
                └──* UserEpisode *──1 User

Episode: owns processing_status (episode-level, for AutoProcessEpisodeJob)
UserEpisode: owns processing_status (per-user, for ProcessEpisodeJob)
```

### Migration Plan

| Migration | Type | Notes |
|-----------|------|-------|
| `add_processing_status_to_episodes` | DDL | Add `processing_status`, `processing_error`, `last_error_at` columns |
| Backfill episode processing_status | Data (in migration) | Set `processing_status = :ready` for episodes that have both transcript and summary |

### Expected Data Volumes

| Table | Expected Records | Access Frequency | Growth Rate |
|-------|-----------------|------------------|-------------|
| episodes | ~500 (current) | Read on every inbox/library page load | ~50/month per active user |
| user_episodes | ~500 (current) | Same as episodes | Same |

Scale is small — no performance concerns with the new columns or stuck-job queries.

---

## 2. API Endpoints

N/A — Level 2 (web-only) project. No API endpoints. All interactions are standard Rails controller actions with Turbo responses.

### New Controller Actions

#### POST /inbox/retry

**Purpose:** Retry a failed episode from the Inbox tab.

**Controller:** `InboxController#retry_processing`

**Behavior:**
1. Find `current_user.user_episodes.find(params[:id])`
2. Call `user_episode.retry_processing!` (resets to `:pending`, clears error state)
3. Enqueue `ProcessEpisodeJob.perform_later(user_episode.id)`
4. Redirect to `inbox_index_path` with notice "Retrying transcription..."

**Authorization:** Session-based (logged-in user). Scoped to `current_user.user_episodes`.

#### POST /library/:id/retry

**Purpose:** Retry a failed episode from the Library tab (list view, distinct from `regenerate` which is for re-summarizing).

**Controller:** `LibraryController#retry_processing`

**Behavior:**
1. Find `current_user.user_episodes.find(params[:id])`
2. Call `user_episode.retry_processing!` (resets to `:pending`, clears error state)
3. Enqueue `ProcessEpisodeJob.perform_later(user_episode.id)`
4. Redirect back with notice "Retrying transcription..."

**Authorization:** Session-based. Scoped to `current_user.user_episodes`.

**Why separate from `regenerate`:** The existing `regenerate` action destroys the summary and sets status to `:summarizing`. The retry action resets to `:pending` and lets the job determine what work is needed (transcript may or may not exist). Different intent, different behavior.

### Modified Routes

```ruby
# config/routes.rb

resources :inbox, only: [:index, :create] do
  collection do
    post :add_to_library
    post :skip
    post :retry_processing    # NEW
    delete :clear
  end
end

resources :library, only: [:index, :show] do
  member do
    post :archive
    post :regenerate
    post :retry_processing    # NEW
  end
end
```

---

## 3. Concurrency Throttling Design

### Approach: Solid Queue `limits_concurrency`

Solid Queue provides built-in concurrency controls via the `limits_concurrency` class method. The infrastructure is already in the schema (`solid_queue_semaphores`, `solid_queue_blocked_executions` tables).

```ruby
# app/jobs/process_episode_job.rb
class ProcessEpisodeJob < ApplicationJob
  queue_as :default
  limits_concurrency key: ->(user_episode_id) { "transcription" }, to: 3

  # ... existing perform logic ...
end
```

```ruby
# app/jobs/auto_process_episode_job.rb
class AutoProcessEpisodeJob < ApplicationJob
  queue_as :default
  limits_concurrency key: ->(episode_id, **) { "transcription" }, to: 3

  # ... existing perform logic ...
end
```

**How it works:**
- Both jobs share the same concurrency key `"transcription"` — this means the limit of 3 applies **globally across both job types**
- When a 4th job tries to execute, Solid Queue blocks it in `solid_queue_blocked_executions` until a slot opens
- `to: 3` allows 3 concurrent transcription/summarization jobs at any time
- Blocked jobs automatically dispatch when a running job completes — no polling needed
- The `key` proc receives the job arguments; using a static string means the limit is global, not per-episode

**Why `to: 3`:** AssemblyAI's rate limits vary by plan, but 3 concurrent is conservative. This can be extracted to a constant or ENV var for tuning.

### No changes to OpmlImportService

`OpmlImportService.process_favorites` continues to enqueue one `ProcessEpisodeJob` per podcast. Solid Queue handles the throttling transparently — the service doesn't need to know about concurrency limits.

---

## 4. Error Handling Improvements

### AssemblyAiClient: Detect Rate Limits

```ruby
# app/services/assembly_ai_client.rb
def transcribe(audio_url)
  # ... existing transcription logic ...
rescue Faraday::TooManyRequestsError => e
  raise RateLimitError, "AssemblyAI rate limit exceeded: #{e.message}"
rescue Faraday::Error => e
  raise Error, "AssemblyAI API error: #{e.message}"
rescue StandardError => e
  raise Error, "AssemblyAI error: #{e.message}"
end
```

**Change:** Add a specific rescue for `Faraday::TooManyRequestsError` (subclass of `Faraday::Error`) **before** the generic `Faraday::Error` catch. This raises `AssemblyAiClient::RateLimitError` (already defined, never used) instead of the generic `Error`.

**Impact on jobs:** Both jobs already rescue `AssemblyAiClient::Error` (parent of `RateLimitError`), so this is fully backwards compatible. The benefit is the error message now says "rate limit exceeded" instead of a generic API error.

### ProcessEpisodeJob: Improve Error Messages

```ruby
# Retryable error handler — improve the message for rate limits
rescue ClaudeClient::RateLimitError, AssemblyAiClient::RateLimitError => e
  handle_retryable_error(user_episode, e, retryable: true)
rescue AssemblyAiClient::Error => e
  handle_retryable_error(user_episode, e, retryable: true)
rescue => e
  user_episode.update!(
    processing_status: :error,
    processing_error: e.message,
    last_error_at: Time.current
  )
end
```

The rescue chain stays the same functionally (all `AssemblyAiClient::Error` subclasses are retryable), but now rate limit errors carry a specific message.

### AutoProcessEpisodeJob: Add Episode-Level State Tracking

```ruby
class AutoProcessEpisodeJob < ApplicationJob
  queue_as :default
  limits_concurrency key: ->(episode_id, **) { "transcription" }, to: 3

  MAX_RETRIES = 5
  BASE_DELAY = 60

  def perform(episode_id, retry_count: 0)
    episode = Episode.find(episode_id)
    return if episode.transcript.present? && episode.summary.present?

    # Step 1: Transcribe
    unless episode.transcript.present?
      episode.update!(processing_status: :transcribing)
      transcript = AssemblyAiClient.transcribe(episode.audio_url)
      episode.create_transcript!(content: transcript.to_json)
    end

    # Step 2: Summarize
    unless episode.summary.present?
      episode.update!(processing_status: :summarizing)
      summary = ClaudeClient.summarize_chunked(episode.transcript.content)
      episode.create_summary!(
        sections: summary["sections"],
        quotes: summary["quotes"]
      )
    end

    episode.update!(processing_status: :ready)

  rescue ClaudeClient::RateLimitError, AssemblyAiClient::Error => e
    handle_retryable_error(episode, episode_id, retry_count, e)
  rescue => e
    episode.update!(
      processing_status: :error,
      processing_error: e.message,
      last_error_at: Time.current
    )
    Rails.logger.error("[AutoProcessEpisodeJob] Episode #{episode_id} failed: #{e.message}")
  end

  private

  def handle_retryable_error(episode, episode_id, retry_count, error)
    new_retry_count = retry_count + 1
    if new_retry_count > MAX_RETRIES
      episode.update!(
        processing_status: :error,
        processing_error: "#{error.message} (exceeded #{MAX_RETRIES} retries)",
        last_error_at: Time.current
      )
      Rails.logger.error("[AutoProcessEpisodeJob] Episode #{episode_id} exceeded #{MAX_RETRIES} retries: #{error.message}")
      return
    end

    delay_seconds = BASE_DELAY * (2 ** (new_retry_count - 1))
    episode.update!(
      processing_error: "Retrying #{new_retry_count}/#{MAX_RETRIES}",
      last_error_at: Time.current
    )
    AutoProcessEpisodeJob.set(wait: delay_seconds.seconds).perform_later(episode_id, retry_count: new_retry_count)
  end
end
```

**Key change:** Episode-level state tracking. Now `AutoProcessEpisodeJob` writes `processing_status`, `processing_error`, and `last_error_at` to the `episodes` table.

---

## 5. Stuck Job Detection

### Approach: Recurring Solid Queue Job

```ruby
# app/jobs/detect_stuck_processing_job.rb
class DetectStuckProcessingJob < ApplicationJob
  queue_as :default

  STUCK_THRESHOLD = 30.minutes

  def perform
    # Detect stuck UserEpisodes
    UserEpisode
      .where(processing_status: [:transcribing, :summarizing])
      .where("updated_at < ?", STUCK_THRESHOLD.ago)
      .find_each do |ue|
        ue.update!(
          processing_status: :error,
          processing_error: "Processing timed out after #{STUCK_THRESHOLD.inspect}",
          last_error_at: Time.current
        )
      end

    # Detect stuck Episodes
    Episode
      .where(processing_status: [:transcribing, :summarizing])
      .where("updated_at < ?", STUCK_THRESHOLD.ago)
      .find_each do |ep|
        ep.update!(
          processing_status: :error,
          processing_error: "Processing timed out after #{STUCK_THRESHOLD.inspect}",
          last_error_at: Time.current
        )
      end
  end
end
```

### Recurring Schedule

```yaml
# config/recurring.yml — add to both production and development
detect_stuck_processing:
  class: DetectStuckProcessingJob
  schedule: every 10 minutes
```

**Why 30-minute threshold:** AssemblyAI transcription of a 3-hour episode can legitimately take 10-15 minutes. 30 minutes provides margin. The `updated_at` column is touched by every `processing_status` transition, so the check measures time since last state change.

---

## 6. View Changes

### Inbox Tab — Add Processing Status and Retry

Add a processing status indicator and retry button to each episode card in `app/views/inbox/index.html.erb`. The indicator follows the same pattern as the Library index view (case statement on `processing_status`), with an additional retry button for the `error` state.

```erb
<%# Inside each episode card, after the metadata div %>
<% if user_episode.processing_status != "pending" || user_episode.error? %>
  <p class="text-sm mt-1">
    <% case user_episode.processing_status %>
    <% when "transcribing" %>
      <span class="text-yellow-600">Transcribing...</span>
    <% when "summarizing" %>
      <span class="text-yellow-600">Generating summary...</span>
    <% when "ready" %>
      <span class="text-green-600">Ready</span>
    <% when "error" %>
      <span class="text-red-600">Failed: <%= user_episode.processing_error %></span>
    <% end %>
  </p>
<% end %>

<%# Add retry button alongside existing Add to Library / Skip buttons %>
<% if user_episode.error? %>
  <%= button_to "Retry",
      retry_processing_inbox_index_path(id: user_episode.id),
      method: :post,
      class: "..." %>
<% end %>
```

### Library Index — Enhance Error Display

Modify the error case in `app/views/library/index.html.erb` to show the error message and a retry button:

```erb
<% when "error" %>
  <span class="text-red-600">Failed: <%= user_episode.processing_error %></span>
<%# Add retry button %>
<% if user_episode.error? %>
  <div class="mt-3 sm:mt-4">
    <%= button_to "Retry",
        retry_processing_library_path(user_episode),
        method: :post,
        class: "inline-block w-full sm:w-auto text-center bg-red-600 text-white px-4 py-2.5 sm:py-2 rounded-lg hover:bg-red-700 transition text-sm font-medium" %>
  </div>
<% end %>
```

### Library Show — Already Handles Error State

The Library show page (`app/views/library/show.html.erb:58-64`) already has full error treatment: red alert with `processing_error` message and a Retry button (wired to `regenerate`). No changes needed here, though the Retry button should be wired to the new `retry_processing` action instead of `regenerate`, since `retry_processing` correctly resets to `:pending`.

### Shared Partial Consideration

Both Inbox and Library display processing status similarly. A shared partial (`app/views/shared/_processing_status.html.erb`) could be extracted, but this is an implementation detail — the architecture doesn't mandate it.

---

## 7. Backwards Compatibility

### Compatibility Matrix

| Feature / Behavior | Web (current) | Impact |
|-------------------|:---:|:---|
| Existing episodes in Library | Full | No change — `processing_status` behavior unchanged |
| Episodes stuck in `transcribing` | **Fix** | Stuck-job detector transitions to `error`, retry button available |
| OPML import with many podcasts | **Fix** | Jobs throttled to 3 concurrent via Solid Queue |
| Inbox episode display | **New** | Now shows processing status and retry button |
| Library index error display | **Enhanced** | Now shows error message and retry button (was just "Error" text) |
| `regenerate` action | Unchanged | Still works for re-summarizing ready episodes |
| New `retry_processing` action | **New** | Available from both Inbox and Library for error-state episodes |

### API Versioning

N/A — no API.

### Data Migration

| Migration | Strategy | Rollback |
|-----------|----------|----------|
| Add `processing_status` to episodes | Column add with default `0` (pending) | Drop columns |
| Backfill episode processing_status | In-migration: set `ready` for episodes with transcript + summary | Re-run with inverse logic (set back to pending) |
| Fix currently-stuck episodes | Rake task: transition `user_episodes` stuck in `transcribing`/`summarizing` with `updated_at` older than 1 hour to `error` | Manual — re-enqueue jobs if needed |

---

## 8. Security Design

### Query Scoping

| Resource | Scoping Chain |
|----------|--------------|
| UserEpisode (inbox retry) | `current_user.user_episodes.find(params[:id])` |
| UserEpisode (library retry) | `current_user.user_episodes.find(params[:id])` |
| Episode (stuck detector) | Unscoped — system job, operates on all episodes |
| UserEpisode (stuck detector) | Unscoped — system job, operates on all user_episodes |

### Authorization

| Action | Permitted Roles | Check |
|--------|----------------|-------|
| Inbox retry | Authenticated user | Session auth + scoped to own user_episodes |
| Library retry | Authenticated user | Session auth + scoped to own user_episodes |
| Stuck job detection | System (recurring job) | No user auth — runs as background job |

### New Attack Surface

| Vector | Risk | Mitigation |
|--------|------|------------|
| Retry spam (user clicks retry repeatedly) | Low — each retry enqueues a new job | `retry_processing!` resets to `:pending`; `ProcessEpisodeJob` checks for existing transcript/summary before calling APIs. Solid Queue concurrency limit prevents flood. |
| Manipulating `params[:id]` to retry another user's episode | None | Scoped via `current_user.user_episodes.find()` — raises RecordNotFound for other users' episodes |

---

## 9. Export Impact

N/A — no exports affected. This project modifies background job behavior and view templates only.

---

## 10. Open Questions for Human Review

| # | Question | Options | Recommendation |
|---|----------|---------|---------------|
| 1 | Concurrency limit value | A: `to: 3` (conservative) / B: `to: 5` (moderate) / C: ENV-configurable | **A: `to: 3`** — start conservative. Easy to increase later by changing a single number. No need for ENV complexity at this scale. |
| 2 | Stuck job threshold | A: 30 minutes / B: 1 hour / C: Configurable | **A: 30 minutes** — AssemblyAI transcription rarely exceeds 15 minutes even for long episodes. 30 min provides 2x margin. |
| 3 | Should `library/show.html.erb` Retry button be rewired from `regenerate` to `retry_processing`? | A: Yes, change to `retry_processing` / B: Keep `regenerate`, it works fine / C: Show both buttons | **A: Yes** — `regenerate` destroys summary and starts from `:summarizing`, which is wrong when transcript is missing. `retry_processing` resets to `:pending` and lets the job determine what work is needed. |

---

## 11. Alternatives Considered

### Alternative 1: Per-Episode Concurrency Key (instead of global)

**Description:** Use `limits_concurrency key: ->(episode_id) { "transcription/#{episode_id}" }` so each episode has its own concurrency slot.

**Pros:** Prevents duplicate processing of the same episode.

**Cons:** Doesn't solve the bulk import problem — 100 different episodes would still create 100 concurrent slots. The global key is what actually throttles the AssemblyAI API calls.

**Why rejected:** The problem is total API throughput, not per-episode parallelism. A global key solves the actual problem.

### Alternative 2: Staggered Enqueue in OpmlImportService (instead of Solid Queue concurrency)

**Description:** Modify `process_favorites` to call `ProcessEpisodeJob.set(wait: index * 30.seconds).perform_later(...)` so jobs are spaced 30 seconds apart.

**Pros:** Simple, no framework features needed.

**Cons:** Doesn't protect against other concurrent sources (feed fetch, manual add-to-library). Delay is arbitrary and doesn't adapt to actual API load. Creates fragile coupling between the import service and API rate limits.

**Why rejected:** Solid Queue concurrency is more robust — it throttles all transcription jobs regardless of source, adapts automatically (jobs unblock as slots open), and requires no arbitrary delay tuning.

### Alternative 3: Refactor AutoProcessEpisodeJob to Operate on UserEpisode (instead of adding Episode-level state)

**Description:** Change `AutoProcessEpisodeJob` to take `user_episode_id` instead of `episode_id`, writing state to the existing `user_episodes` fields.

**Pros:** No schema change. Single state tracking location.

**Cons:** `FetchPodcastFeedJob` creates UserEpisodes for all subscribers of a podcast. If a podcast has 5 subscribers, this would create 5 `AutoProcessEpisodeJob`s — one per user — each trying to transcribe the same episode. Currently, the episode-level job correctly transcribes once and shares the result.

**Why rejected:** The episode-level job design is correct — transcribe once, share across users. Adding lightweight state columns to Episode preserves this pattern while adding error visibility.

---

## 12. Summary

### Files to Create

| File | Purpose |
|------|---------|
| `db/migrate/XXXXXXXX_add_processing_status_to_episodes.rb` | Add processing state columns to episodes table |
| `app/jobs/detect_stuck_processing_job.rb` | Recurring job to detect and timeout stuck episodes |

### Files to Modify

| File | Changes |
|------|---------|
| `app/models/episode.rb` | Add `processing_status` enum |
| `app/models/user_episode.rb` | Add `retry_processing!` method |
| `app/services/assembly_ai_client.rb` | Add `Faraday::TooManyRequestsError` rescue to raise `RateLimitError` |
| `app/jobs/process_episode_job.rb` | Add `limits_concurrency`, rescue `RateLimitError` specifically |
| `app/jobs/auto_process_episode_job.rb` | Add `limits_concurrency`, add episode-level state tracking |
| `app/controllers/inbox_controller.rb` | Add `retry_processing` action |
| `app/controllers/library_controller.rb` | Add `retry_processing` action |
| `config/routes.rb` | Add retry_processing routes for inbox and library |
| `config/recurring.yml` | Add `detect_stuck_processing` schedule |
| `app/views/inbox/index.html.erb` | Add processing status indicator and retry button |
| `app/views/library/index.html.erb` | Enhance error display with message and retry button |
| `app/views/library/show.html.erb` | Rewire Retry button to `retry_processing` (from `regenerate`) |

---

## Approval Checklist

> **This architecture proposal requires human review and approval before the gameplan is generated.**

### Reviewer: Dave
### Date: 2/10/2026
### Status: Approved

#### Must Verify
- [x] Data model is architecturally sound (episode-level processing_status columns)
- [x] Solid Queue `limits_concurrency` approach is appropriate for throttling
- [x] Error handling improvements cover all failure modes
- [x] Stuck job detection approach is sound (recurring job + 30-min threshold)
- [x] Migration strategy is safe (column additions + backfill)

#### Should Check
- [x] Retry action design (separate from regenerate) makes sense
- [x] Inbox tab UX parity with Library tab is correct
- [x] Concurrency limit of 3 is appropriate for the AssemblyAI plan
- [x] No conflicts with in-progress work or upcoming changes

#### Notes
[Reviewer notes, modifications requested, or rejection reasons]
