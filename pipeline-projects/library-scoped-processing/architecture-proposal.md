---
pipeline_stage: 2
pipeline_stage_name: architecture
pipeline_project: "library-scoped-processing"
pipeline_started_at: "2026-02-17T08:28:01-0500"
pipeline_completed_at: "2026-02-17T08:28:32-0500"
pipeline_approved_at: "2026-02-17"
---

# Library-Scoped Processing — Architecture Proposal

> **Generated by:** Pipeline Stage 2 (Architecture)
> **Date:** 2026-02-17
> **PRD:** `pipeline-projects/library-scoped-processing/prd.md`
> **Discovery Report:** `pipeline-projects/library-scoped-processing/discovery-report.md`

---

## 1. Data Model Changes

### New Tables

None.

### Modified Tables

None. No schema changes are required — the existing `user_episodes` table already has the `location` and `processing_status` columns needed to support library-scoped queries.

### Models

No model changes. The relevant existing model code:

```ruby
# app/models/user_episode.rb (existing, no changes)
class UserEpisode < ApplicationRecord
  enum :location, { inbox: 0, library: 1, archive: 2, trash: 3 }
  enum :processing_status, { pending: 0, downloading: 1, transcribing: 2,
                              summarizing: 3, ready: 4, error: 5 }

  scope :in_library, -> { where(location: :library) }

  def move_to_library!
    update!(location: :library, processing_status: :pending, trashed_at: nil,
            retry_count: 0, next_retry_at: nil, processing_error: nil)
  end
end
```

### Migration Plan

No migrations needed.

### Expected Data Volumes

No change — the existing tables are unaffected. Query patterns change but data volumes do not.

---

## 2. API Endpoints

N/A — this project does not expose or modify an API. All changes are to backend jobs and mailers.

---

## 3. Backwards Compatibility

N/A — no backwards compatibility concerns. Single-platform web app with no external consumers.

---

## 4. Security Design

### Authorization

No new data access paths are introduced. All existing access patterns remain unchanged:

| Action | Current Auth | After Change |
|--------|-------------|-------------|
| Digest email query | Scoped to `user.id` via subscription join | Scoped to `user.id` via `user_episodes.user_id` — same or tighter |
| Feed fetch job | No user context (system job) | No change |
| Library add | `current_user.user_episodes` | No change |
| Library retry | `current_user.user_episodes.find(params[:id])` | No change |

### New Attack Surface

None. The changes narrow query scope (from all subscribed episodes to library episodes only), which reduces rather than expands attack surface.

---

## 5. Export Impact

N/A — no export impact.

---

## 6. Detailed Design

This section describes the exact changes needed, file by file.

### 6.1 Shared Query Helper — `Episode.library_ready_since`

The library-ready episodes query is used in three places (DigestMailer class method, DigestMailer instance fallback, SendDailyDigestJob eligibility check). Extract to a scope on `Episode` to eliminate drift risk.

**Add to `app/models/episode.rb`:**

```ruby
scope :library_ready_since, ->(user, since) {
  joins(:user_episodes, :podcast)
    .where(user_episodes: { user_id: user.id, location: :library, processing_status: :ready })
    .where("user_episodes.updated_at > ?", since)
    .includes(:summary)
    .order("podcasts.title ASC, episodes.published_at DESC")
}
```

Key design choices:
- **`.joins(:user_episodes, :podcast)`** — explicit join on both tables. The podcast join ensures `ORDER BY podcasts.title` has a SQL join to reference (not relying on `includes` which may use separate queries).
- **`.includes(:summary)`** — eager-loads summaries for rendering. This is a separate `includes` from the podcast join because summaries don't need a SQL join, just preloading.
- **`user_episodes.updated_at > since`** — proxy for "became ready". When `ProcessEpisodeJob` completes, it calls `user_episode.update!(processing_status: :ready, ...)` which sets `updated_at`. Acceptable for a single-user app.
- **Returns an ActiveRecord relation** — callers can chain `.group_by(&:podcast)` for the mailer or `.exists?` for the eligibility check.

### 6.2 DigestMailer — Use Shared Scope

**Current behavior:** Queries all episodes from subscribed podcasts created after `digest_sent_at`.

**New behavior:** Queries library episodes for this user with `processing_status = ready` and `updated_at` within the eligibility window.

The query appears in two places within `digest_mailer.rb` (class method for eager load, instance method for deliver_later fallback). Both now call the shared scope.

**New `since` calculation (24-hour cap):**

```ruby
since ||= [user.digest_sent_at, 24.hours.ago].compact.max
```

This ensures: if `digest_sent_at` is nil or older than 24 hours, cap at 24 hours. Prevents a backlog of old episodes appearing after a gap in digest delivery.

**New query (replaces both occurrences):**

```ruby
since ||= [user.digest_sent_at, 24.hours.ago].compact.max

episodes_by_show = Episode
  .library_ready_since(user, since)
  .group_by(&:podcast)
```

**Subject line change (DIG-003):**

```ruby
# Before:
subject: "Your podcasts this morning — #{@episode_count} new episode#{'s' unless @episode_count == 1}"

# After:
subject: "Your library — #{@episode_count} episode#{'s' unless @episode_count == 1} ready"
```

**NullMail guard (line 29):** No change needed — it already returns `NullMail` when `episode_count` is zero, which handles DIG-004.

### 6.3 SendDailyDigestJob — Use Shared Scope

**Current `has_new_episodes?`:**

```ruby
def has_new_episodes?(user)
  since = user.digest_sent_at || 1.day.ago
  Episode
    .joins(podcast: :subscriptions)
    .where(subscriptions: { user_id: user.id })
    .where("episodes.created_at > ?", since)
    .exists?
end
```

**New `has_new_episodes?`:**

```ruby
def has_new_episodes?(user)
  since = [user.digest_sent_at, 24.hours.ago].compact.max
  Episode.library_ready_since(user, since).exists?
end
```

Same scope, same 24-hour cap, just calls `.exists?` instead of materializing results.

### 6.4 FetchPodcastFeedJob — Remove Auto-Processing

Remove line 35 from `app/jobs/fetch_podcast_feed_job.rb`:

```ruby
# DELETE this line:
AutoProcessEpisodeJob.perform_later(episode.id)

# And the comment on line 34:
# Auto-process: enqueue transcription + summarization
```

The rest of the job stays intact. New episodes still create `Episode` records and `UserEpisode` inbox entries.

### 6.5 AutoProcessEpisodeJob — Delete

Delete these files:
- `app/jobs/auto_process_episode_job.rb`
- `spec/jobs/auto_process_episode_job_spec.rb`
- `spec/jobs/auto_process_episode_job_state_tracking_spec.rb`

Rationale: The job has exactly one call site (FetchPodcastFeedJob line 35), which is being removed. Dead code is confusing — it suggests the job is still used somewhere. Deleting cleanly communicates intent. Git history preserves the code if needed.

### 6.6 DetectStuckProcessingJob — Remove Episode Detection Block

Remove lines 19-29 (the Episode stuck detection block) from `app/jobs/detect_stuck_processing_job.rb`. Keep the UserEpisode block (lines 7-17) which is still needed for `ProcessEpisodeJob`.

Rationale: Episode-level processing is being deleted (`AutoProcessEpisodeJob` removal). The detection block should go with it. Old episode-level stuck records will age out naturally since no new episode-level processing is enqueued.

**After change:**

```ruby
class DetectStuckProcessingJob < ApplicationJob
  queue_as :default

  STUCK_THRESHOLD = 30.minutes + 1.second

  def perform
    UserEpisode
      .where(processing_status: [ :transcribing, :summarizing ])
      .where("updated_at < ?", STUCK_THRESHOLD.ago)
      .find_each do |ue|
        ue.update!(
          processing_status: :error,
          processing_error: "Processing timed out after #{STUCK_THRESHOLD.inspect}",
          last_error_at: Time.current
        )
      end
  end
end
```

### 6.7 Digest `since` Race Protection

The current DigestMailer has a race condition guard (CLAUDE.md documents this): the `since` parameter is captured eagerly and passed through to `deliver_later` serialization, so that if `digest_sent_at` is bumped between scheduling and delivery, the original cutoff is preserved.

This pattern must be preserved with the new query. It already works — the `since` parameter flows through to both class and instance methods, and the new query uses `since` the same way. No architectural change needed.

---

## 7. Open Questions for Human Review

No open questions remain. All decisions have been resolved:

| # | Decision | Resolution |
|---|----------|-----------|
| 1 | Extract shared query helper vs keep inline | Extract to `Episode.library_ready_since(user, since)` — eliminates drift risk across 3 call sites |
| 2 | 24-hour digest cap | Use `[digest_sent_at, 24.hours.ago].compact.max` — prevents stale backlogs |
| 3 | DetectStuckProcessingJob Episode block | Remove — Episode-level processing is being deleted |
| 4 | AutoProcessEpisodeJob disposal | Delete entirely (job + both spec files) |
| 5 | Explicit podcast join in query | Yes — `.joins(:user_episodes, :podcast)` ensures robust ORDER BY |

---

## 8. Alternatives Considered

### Keep Digest Query Inline (Not Extracted)

**Description:** Keep the library-ready query inline in each of the 3 call sites rather than extracting to a shared scope.

**Pros:** No indirection. Each call site is self-contained and readable.

**Cons:** Three copy-paste query sites that must stay synchronized. Drift risk is real — the mailer's class method and instance fallback already demonstrate this duplication pattern.

**Why rejected:** The reviewer flagged drift risk as a concrete concern. A shared scope eliminates it with minimal indirection. The `.exists?` call in `has_new_episodes?` chains naturally on the same scope.

### Keep AutoProcessEpisodeJob as Dead Code

**Description:** Leave the job class in place but don't call it.

**Pros:** Zero risk of breaking anything. Easier to re-enable if the decision is reversed.

**Cons:** Dead code is confusing. Future developers (or agents) may think it's still active. The job has exactly one call site, so re-enabling is trivial even after deletion (just re-add the file).

**Why rejected:** Clean deletion is safer than dead code for a single-developer project. Git history preserves the code if needed.

---

## 9. Architecture Decision Records

No decisions in this project warranted a standalone ADR. The changes are behavioral (query changes, line deletions, file removal) with no genuinely contested architectural alternatives.

---

## 10. Summary

### Files to Create

None.

### Files to Modify

| File | Changes |
|------|---------|
| `app/models/episode.rb` | Add `library_ready_since` scope. |
| `app/mailers/digest_mailer.rb` | Replace subscription-scoped query with `Episode.library_ready_since` in both class and instance methods (lines 20-26, 80-86). Add 24-hour cap to `since` calculation. Update subject line (line 105). |
| `app/jobs/send_daily_digest_job.rb` | Replace subscription-scoped `has_new_episodes?` query with `Episode.library_ready_since(...).exists?` (lines 37-44). Add 24-hour cap. |
| `app/jobs/fetch_podcast_feed_job.rb` | Remove `AutoProcessEpisodeJob.perform_later(episode.id)` call and comment (lines 34-35). |
| `app/jobs/detect_stuck_processing_job.rb` | Remove Episode stuck detection block (lines 19-29). |

### Files to Delete

| File | Reason |
|------|--------|
| `app/jobs/auto_process_episode_job.rb` | No longer called — deleted alongside its single call site. |
| `spec/jobs/auto_process_episode_job_spec.rb` | Tests for deleted job. |
| `spec/jobs/auto_process_episode_job_state_tracking_spec.rb` | State tracking tests for deleted job. |

### Test Files to Update

| File | Changes |
|------|---------|
| `spec/mailers/digest_mailer_spec.rb` | Update to verify library-only episode inclusion and 24-hour cap behavior. |
| `spec/jobs/send_daily_digest_job_spec.rb` | Update to verify library-only eligibility check and 24-hour cap. |
| `spec/jobs/fetch_podcast_feed_job_spec.rb` | Remove AutoProcessEpisodeJob enqueue assertions. |
| `spec/jobs/detect_stuck_processing_job_spec.rb` | Remove Episode timeout detection tests. |

---

## Approval Checklist

> **This architecture proposal requires human review and approval before the gameplan is generated.**

### Reviewer: Dave
### Date: 2026-02-17
### Status: Approved

#### Must Verify
- [x] Shared scope `Episode.library_ready_since(user, since)` is correct (joins user_episodes + podcast, filters by location + processing_status + updated_at)
- [x] Using `user_episodes.updated_at` as a proxy for "became ready" is acceptable
- [x] 24-hour digest cap (`[digest_sent_at, 24.hours.ago].compact.max`) is correct behavior
- [x] Deleting `AutoProcessEpisodeJob` and both spec files is acceptable
- [x] Removing Episode stuck detection from `DetectStuckProcessingJob` is acceptable
- [x] The `since` race protection pattern is preserved correctly

#### Should Check
- [x] Subject line change ("Your library — N episodes ready") is the desired framing
- [x] No conflicts with in-progress work or upcoming changes

#### Notes
[Reviewer notes, modifications requested, or rejection reasons]
